{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e6953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit.Chem import rdchem, AllChem\n",
    "\n",
    "# 选择设备：GPU如果可用，否则使用CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc6c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据预处理: 从SMILES生成分子图和特征\n",
    "class FeaturizationParameters:\n",
    "    MAX_ATOMIC_NUM = 118  # 最大原子序号\n",
    "\n",
    "    ATOM_FEATURES = {\n",
    "        'atomic_num': list(range(1, MAX_ATOMIC_NUM + 1)),  # 原子序号（1-118）\n",
    "        'degree': [0, 1, 2, 3, 4, 5],  # 原子的度\n",
    "        'formal_charge': [-1, 0, 1],  # 原子的形式电荷\n",
    "        'chiral_tag': [0, 1, 2, 3],  # 手性信息\n",
    "        'num_Hs': [0, 1, 2, 3],  # 连接的H原子数\n",
    "        'hybridization': [\n",
    "            rdchem.HybridizationType.SP,\n",
    "            rdchem.HybridizationType.SP2,\n",
    "            rdchem.HybridizationType.SP3,\n",
    "            rdchem.HybridizationType.SP3D,\n",
    "            rdchem.HybridizationType.SP3D2\n",
    "        ],\n",
    "        'explicit_valence': [0, 1, 2, 3, 4, 5, 6],  # 显式化合价\n",
    "        'implicit_valence': [0, 1, 2, 3],  # 隐式化合价\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # 一个通用的函数用于独热编码\n",
    "    def one_hot_encoding(self, value, feature_list):\n",
    "        return [1 if x == value else 0 for x in feature_list]\n",
    "    \n",
    "def smiles_to_graph(smiles, featurization_params):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Invalid SMILES string: {smiles}\")\n",
    "    \n",
    "    # 获取相关的原子特征并进行独热编码\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        # 使用 FeaturizationParameters 类中的 `one_hot_encoding` 方法进行独热编码\n",
    "        features = []\n",
    "        \n",
    "        # 对每个特征进行独热编码\n",
    "        features += featurization_params.one_hot_encoding(atom.GetAtomicNum(), featurization_params.ATOM_FEATURES['atomic_num'])  # 原子序数\n",
    "        features += featurization_params.one_hot_encoding(atom.GetFormalCharge(), featurization_params.ATOM_FEATURES['formal_charge'])  # 电荷\n",
    "        features += featurization_params.one_hot_encoding(atom.GetNumRadicalElectrons(), [0, 1, 2, 3])  # 自由基电子数（假设只有0到3个）\n",
    "        features.append(1 if atom.GetIsAromatic() else 0)  # 是否芳香环\n",
    "        features += featurization_params.one_hot_encoding(atom.GetDegree(), featurization_params.ATOM_FEATURES['degree'])  # 度数\n",
    "        features += featurization_params.one_hot_encoding(atom.GetExplicitValence(), featurization_params.ATOM_FEATURES['explicit_valence'])  # 显式化合价\n",
    "        features += featurization_params.one_hot_encoding(atom.GetImplicitValence(), featurization_params.ATOM_FEATURES['implicit_valence'])  # 隐式化合价\n",
    "        features += featurization_params.one_hot_encoding(atom.GetHybridization(), featurization_params.ATOM_FEATURES['hybridization'])  # 杂化类型\n",
    "        features.append(atom.GetTotalNumHs())  # 连接的氢原子数（不进行独热编码，可以直接使用数值）\n",
    "        \n",
    "        atom_features.append(features)\n",
    "\n",
    "    # 获取键特征\n",
    "    bonds = []\n",
    "    bond_types = []\n",
    "    for bond in mol.GetBonds():\n",
    "        bond_types.append(bond.GetBondTypeAsDouble())\n",
    "        bonds.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    bonds = np.array(bonds, dtype=np.int64)  # 使用np.int64代替np.long\n",
    "    bond_types = np.array(bond_types, dtype=np.float32)\n",
    "\n",
    "    # 将图数据结构化\n",
    "    data = Data(\n",
    "        x=torch.tensor(atom_features, dtype=torch.float32),  # 确保x是浮点型\n",
    "        edge_index=torch.tensor(bonds, dtype=torch.long).t().contiguous(),\n",
    "        edge_attr=torch.tensor(bond_types, dtype=torch.float32)\n",
    "    )\n",
    "    return data, mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61565471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 模型定义: 图神经网络 + MLP\n",
    "class GNN_MLP_Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_mol_features, dropout_prob=0.5):\n",
    "        super(GNN_MLP_Model, self).__init__()\n",
    "\n",
    "        # 图卷积层\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)  \n",
    "        \n",
    "        # MLP部分\n",
    "        self.fc1 = nn.Linear(hidden_dim + num_mol_features, hidden_dim)  # 拼接后的维度\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)  # 新增的全连接层\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)  # 输出层\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, data, mol_features):\n",
    "        # 获取图的数据\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        # 通过图卷积层并应用 ReLU 激活函数\n",
    "        x = torch.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = torch.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = torch.relu(self.conv3(x, edge_index, edge_attr))  # 第四层卷积\n",
    "        \n",
    "        # 图的全局池化：使用平均池化\n",
    "        x = torch.mean(x, dim=0)  # 对节点特征进行池化\n",
    "        \n",
    "        # 确保分子特征的形状正确\n",
    "        mol_features = mol_features.view(-1, mol_features.size(-1))  # 确保形状正确\n",
    "        \n",
    "        # 拼接图特征和分子特征\n",
    "        combined_features = torch.cat([x.unsqueeze(0), mol_features], dim=-1)  # 拼接操作\n",
    "        \n",
    "\n",
    "        # 通过全连接层并应用 ReLU 激活函数\n",
    "        x = torch.relu(self.fc1(combined_features))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6673fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 训练过程\n",
    "def train_kfold(model, data, mol_features, targets, epochs=100, lr=1e-3, num_splits=10):\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Metrics storage for each fold\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    # Data for saving predictions and actual values\n",
    "    predictions_and_actuals = []\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     mol_features_scaled = scaler.fit_transform(mol_features.cpu().numpy())\n",
    "\n",
    "\n",
    "    # Training and evaluating each fold\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(data)):\n",
    "        print(f\"\\nTraining Fold {fold + 1}/{num_splits}...\")\n",
    "\n",
    "        # Split data\n",
    "        train_data = [data[i] for i in train_index]\n",
    "        val_data = [data[i] for i in val_index]\n",
    "        mol_features_train = mol_features[train_index].clone().detach().to(device)\n",
    "        mol_features_val = mol_features[val_index].clone().detach().to(device)\n",
    "        targets_train = targets[train_index].clone().detach().to(device)\n",
    "        targets_val = targets[val_index].clone().detach().to(device)\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-3)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10, verbose=True)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for i in range(len(train_data)):\n",
    "                data_ = train_data[i].to(device)\n",
    "                mol_feature = mol_features_train[i].to(device)\n",
    "                target = targets_train[i]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data_, mol_feature)\n",
    "                loss = loss_fn(output, target)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation loss\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for i in range(len(val_data)):\n",
    "                    data_ = val_data[i].to(device)\n",
    "                    mol_feature = mol_features_val[i].to(device)\n",
    "                    target = targets_val[i]\n",
    "\n",
    "                    output = model(data_, mol_feature)\n",
    "                    loss = loss_fn(output, target)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {total_loss / len(train_data):.4f}, Validation Loss: {val_loss / len(val_data):.4f}\")\n",
    "\n",
    "            # Save the best model for this fold\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), f\"best_model_fold_{fold + 1}.pth\")\n",
    "                print('best model find! loss:',val_loss, best_val_loss)\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # Load the best model and evaluate\n",
    "        model.load_state_dict(torch.load(f\"best_model_fold_{fold + 1}.pth\"))\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        rmse, mae, r2 = calculate_metrics(val_data, mol_features_val, targets_val)\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        print(f\"Fold {fold + 1} -> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    # Summary statistics\n",
    "    rmse_mean, rmse_std = np.mean(rmse_list), np.std(rmse_list)\n",
    "    mae_mean, mae_std = np.mean(mae_list), np.std(mae_list)\n",
    "    r2_mean, r2_std = np.mean(r2_list), np.std(r2_list)\n",
    "\n",
    "    print(\"\\nCross-validation Results:\")\n",
    "    print(f\"RMSE Mean: {rmse_mean:.4f}, Std: {rmse_std:.4f}\")\n",
    "    print(f\"MAE Mean: {mae_mean:.4f}, Std: {mae_std:.4f}\")\n",
    "    print(f\"R² Mean: {r2_mean:.4f}, Std: {r2_std:.4f}\")\n",
    "\n",
    "    return rmse_mean, mae_mean, r2_mean, rmse_std, mae_std, r2_std\n",
    "\n",
    "\n",
    "def calculate_metrics(data, mol_features, targets):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data_ = data[i].to(device)\n",
    "            mol_feature = mol_features[i].to(device)\n",
    "            target = targets[i]\n",
    "\n",
    "            output = model(data_, mol_feature)\n",
    "            predictions.append(output.item())\n",
    "            true_values.append(target.item())\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    true_values = np.array(true_values)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "    mae = mean_absolute_error(true_values, predictions)\n",
    "    r2 = r2_score(true_values, predictions)\n",
    "\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def get_predictions(model, data, mol_features, targets):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data_ = data[i].to(device)\n",
    "            mol_feature = mol_features[i].to(device)\n",
    "            target = targets[i]\n",
    "\n",
    "            output = model(data_, mol_feature)\n",
    "            predictions.append(output.item())\n",
    "            actuals.append(target.item())\n",
    "\n",
    "    return np.array(predictions), np.array(actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a2885",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# 函数加载完毕，处理数据(主函数部分)\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb809a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "data = pd.read_csv(r\"input_zz.csv\")  # 替换为你的数据文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6510ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.训练集与测试集随机划分:完全随机划分\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f952b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机旋转分子对训练数据进行数据增强\n",
    "def randomize_mol(mol):\n",
    "    try:\n",
    "        ans = list(range(mol.GetNumAtoms()))\n",
    "        np.random.shuffle(ans)\n",
    "        nm = Chem.RenumberAtoms(mol, ans)\n",
    "        return nm\n",
    "    except:\n",
    "        return float('nan')\n",
    "\n",
    "def dataAug(df, epoch):\n",
    "    df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "    dfold = df.copy()\n",
    "    for i in range (epoch-1):\n",
    "        dftmp = dfold.copy()\n",
    "        dftmp['mol'] = dftmp['mol'].apply(randomize_mol)\n",
    "        dftmp['SMILES'] = dftmp['mol'].apply(Chem.MolToSmiles)\n",
    "        df = pd.concat([df, dftmp])\n",
    "    df = df.drop('mol', axis=1)\n",
    "    return df\n",
    "\n",
    "train_data = dataAug(train_data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89cfe9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = train_data['SMILES'].tolist()\n",
    "train_targets = train_data['IE'].values\n",
    "mol_features = train_data.drop(columns=['SMILES', 'IE']).values\n",
    "\n",
    "# 分子图特征提取\n",
    "featurization_params = FeaturizationParameters()\n",
    "data_list = []\n",
    "for smiles in smiles_list:\n",
    "    data, mol = smiles_to_graph(smiles, featurization_params)  # 传递 featurization_params\n",
    "    #print(data)\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40b3fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据移到CUDA设备\n",
    "data_list = [data.to(device) for data in data_list]\n",
    "mol_features = torch.tensor(mol_features, dtype=torch.float32).to(device)\n",
    "train_targets = torch.tensor(train_targets, dtype=torch.float32).to(device)\n",
    "\n",
    "# 创建模型并移动到GPU\n",
    "input_dim = 149  # 每个原子特征包含10个值\n",
    "hidden_dim = 300 #隐藏层\n",
    "output_dim = 1  # LD50预测\n",
    "num_mol_features = mol_features.shape[1]  # 分子特征的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02f839da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN_MLP_Model(input_dim, hidden_dim, output_dim, num_mol_features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#钩子函数，显示每一行输出内容\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Module {module.__class__.__name__},Input:{input}, Output: {output}\")\n",
    "model.conv1.register_forward_hook(hook_fn)\n",
    "model.conv3.register_forward_hook(hook_fn)\n",
    "model.fc1.register_forward_hook(hook_fn)\n",
    "model.fc3.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e0b5d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/10...\n",
      "Epoch 1/100, Train Loss: 0.0616, Validation Loss: 0.0468\n",
      "loss: 3.836489469449589 3.836489469449589\n",
      "Epoch 2/100, Train Loss: 0.0393, Validation Loss: 0.0476\n",
      "Epoch 3/100, Train Loss: 0.0381, Validation Loss: 0.0477\n",
      "Epoch 4/100, Train Loss: 0.0373, Validation Loss: 0.0476\n",
      "Epoch 5/100, Train Loss: 0.0367, Validation Loss: 0.0476\n",
      "Epoch 6/100, Train Loss: 0.0361, Validation Loss: 0.0476\n",
      "Epoch 7/100, Train Loss: 0.0355, Validation Loss: 0.0476\n",
      "Epoch 8/100, Train Loss: 0.0350, Validation Loss: 0.0475\n",
      "Epoch 9/100, Train Loss: 0.0345, Validation Loss: 0.0476\n",
      "Epoch 10/100, Train Loss: 0.0340, Validation Loss: 0.0476\n",
      "Epoch 11/100, Train Loss: 0.0336, Validation Loss: 0.0477\n",
      "Epoch 12/100, Train Loss: 0.0332, Validation Loss: 0.0477\n",
      "Epoch 00012: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 13/100, Train Loss: 0.0327, Validation Loss: 0.0474\n",
      "Epoch 14/100, Train Loss: 0.0324, Validation Loss: 0.0475\n",
      "Epoch 15/100, Train Loss: 0.0321, Validation Loss: 0.0476\n",
      "Epoch 16/100, Train Loss: 0.0318, Validation Loss: 0.0477\n",
      "Epoch 17/100, Train Loss: 0.0315, Validation Loss: 0.0478\n",
      "Epoch 18/100, Train Loss: 0.0312, Validation Loss: 0.0479\n",
      "Epoch 19/100, Train Loss: 0.0310, Validation Loss: 0.0480\n",
      "Epoch 20/100, Train Loss: 0.0308, Validation Loss: 0.0480\n",
      "Epoch 21/100, Train Loss: 0.0305, Validation Loss: 0.0482\n",
      "Epoch 22/100, Train Loss: 0.0303, Validation Loss: 0.0483\n",
      "Epoch 23/100, Train Loss: 0.0301, Validation Loss: 0.0483\n",
      "Epoch 00023: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 24/100, Train Loss: 0.0298, Validation Loss: 0.0479\n",
      "Epoch 25/100, Train Loss: 0.0296, Validation Loss: 0.0479\n",
      "Epoch 26/100, Train Loss: 0.0294, Validation Loss: 0.0481\n",
      "Epoch 27/100, Train Loss: 0.0292, Validation Loss: 0.0481\n",
      "Epoch 28/100, Train Loss: 0.0291, Validation Loss: 0.0481\n",
      "Epoch 29/100, Train Loss: 0.0289, Validation Loss: 0.0482\n",
      "Epoch 30/100, Train Loss: 0.0288, Validation Loss: 0.0481\n",
      "Epoch 31/100, Train Loss: 0.0286, Validation Loss: 0.0482\n",
      "Epoch 32/100, Train Loss: 0.0285, Validation Loss: 0.0482\n",
      "Epoch 33/100, Train Loss: 0.0284, Validation Loss: 0.0483\n",
      "Epoch 34/100, Train Loss: 0.0283, Validation Loss: 0.0483\n",
      "Epoch 00034: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 35/100, Train Loss: 0.0280, Validation Loss: 0.0478\n",
      "Epoch 36/100, Train Loss: 0.0279, Validation Loss: 0.0478\n",
      "Epoch 37/100, Train Loss: 0.0278, Validation Loss: 0.0479\n",
      "Epoch 38/100, Train Loss: 0.0277, Validation Loss: 0.0479\n",
      "Epoch 39/100, Train Loss: 0.0276, Validation Loss: 0.0479\n",
      "Epoch 40/100, Train Loss: 0.0275, Validation Loss: 0.0479\n",
      "Epoch 41/100, Train Loss: 0.0274, Validation Loss: 0.0480\n",
      "Epoch 42/100, Train Loss: 0.0274, Validation Loss: 0.0479\n",
      "Epoch 43/100, Train Loss: 0.0273, Validation Loss: 0.0480\n",
      "Epoch 44/100, Train Loss: 0.0272, Validation Loss: 0.0479\n",
      "Epoch 45/100, Train Loss: 0.0272, Validation Loss: 0.0479\n",
      "Epoch 00045: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 46/100, Train Loss: 0.0269, Validation Loss: 0.0474\n",
      "Epoch 47/100, Train Loss: 0.0268, Validation Loss: 0.0474\n",
      "Epoch 48/100, Train Loss: 0.0268, Validation Loss: 0.0474\n",
      "Epoch 49/100, Train Loss: 0.0267, Validation Loss: 0.0474\n",
      "Epoch 50/100, Train Loss: 0.0267, Validation Loss: 0.0474\n",
      "Epoch 51/100, Train Loss: 0.0266, Validation Loss: 0.0474\n",
      "Epoch 52/100, Train Loss: 0.0266, Validation Loss: 0.0473\n",
      "Epoch 53/100, Train Loss: 0.0265, Validation Loss: 0.0473\n",
      "Epoch 54/100, Train Loss: 0.0265, Validation Loss: 0.0473\n",
      "Epoch 55/100, Train Loss: 0.0264, Validation Loss: 0.0472\n",
      "Epoch 56/100, Train Loss: 0.0264, Validation Loss: 0.0472\n",
      "Epoch 00056: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 57/100, Train Loss: 0.0262, Validation Loss: 0.0467\n",
      "loss: 3.832546981589985 3.832546981589985\n",
      "Epoch 58/100, Train Loss: 0.0261, Validation Loss: 0.0467\n",
      "loss: 3.8285430696996627 3.8285430696996627\n",
      "Epoch 59/100, Train Loss: 0.0260, Validation Loss: 0.0466\n",
      "loss: 3.8241269726422615 3.8241269726422615\n",
      "Epoch 60/100, Train Loss: 0.0260, Validation Loss: 0.0467\n",
      "Epoch 61/100, Train Loss: 0.0260, Validation Loss: 0.0466\n",
      "loss: 3.820788668410387 3.820788668410387\n",
      "Epoch 62/100, Train Loss: 0.0259, Validation Loss: 0.0466\n",
      "loss: 3.819085019349586 3.819085019349586\n",
      "Epoch 63/100, Train Loss: 0.0259, Validation Loss: 0.0466\n",
      "Epoch 64/100, Train Loss: 0.0259, Validation Loss: 0.0466\n",
      "Epoch 65/100, Train Loss: 0.0258, Validation Loss: 0.0466\n",
      "Epoch 66/100, Train Loss: 0.0258, Validation Loss: 0.0466\n",
      "Epoch 67/100, Train Loss: 0.0258, Validation Loss: 0.0466\n",
      "loss: 3.8173031523328973 3.8173031523328973\n",
      "Epoch 68/100, Train Loss: 0.0258, Validation Loss: 0.0465\n",
      "loss: 3.810794544755481 3.810794544755481\n",
      "Epoch 69/100, Train Loss: 0.0257, Validation Loss: 0.0465\n",
      "Epoch 70/100, Train Loss: 0.0257, Validation Loss: 0.0466\n",
      "Epoch 71/100, Train Loss: 0.0257, Validation Loss: 0.0466\n",
      "Epoch 72/100, Train Loss: 0.0256, Validation Loss: 0.0465\n",
      "loss: 3.80996705837606 3.80996705837606\n",
      "Epoch 73/100, Train Loss: 0.0256, Validation Loss: 0.0465\n",
      "Epoch 74/100, Train Loss: 0.0256, Validation Loss: 0.0465\n",
      "Epoch 75/100, Train Loss: 0.0256, Validation Loss: 0.0465\n",
      "Epoch 76/100, Train Loss: 0.0255, Validation Loss: 0.0465\n",
      "Epoch 77/100, Train Loss: 0.0255, Validation Loss: 0.0464\n",
      "loss: 3.8067764038496534 3.8067764038496534\n",
      "Epoch 78/100, Train Loss: 0.0255, Validation Loss: 0.0464\n",
      "Epoch 79/100, Train Loss: 0.0254, Validation Loss: 0.0465\n",
      "Epoch 80/100, Train Loss: 0.0254, Validation Loss: 0.0465\n",
      "Epoch 81/100, Train Loss: 0.0254, Validation Loss: 0.0465\n",
      "Epoch 82/100, Train Loss: 0.0254, Validation Loss: 0.0465\n",
      "Epoch 83/100, Train Loss: 0.0254, Validation Loss: 0.0465\n",
      "Epoch 84/100, Train Loss: 0.0253, Validation Loss: 0.0464\n",
      "loss: 3.8045592686976306 3.8045592686976306\n",
      "Epoch 85/100, Train Loss: 0.0253, Validation Loss: 0.0465\n",
      "Epoch 86/100, Train Loss: 0.0253, Validation Loss: 0.0464\n",
      "Epoch 87/100, Train Loss: 0.0253, Validation Loss: 0.0464\n",
      "Epoch 88/100, Train Loss: 0.0253, Validation Loss: 0.0464\n",
      "loss: 3.8032818330648297 3.8032818330648297\n",
      "Epoch 89/100, Train Loss: 0.0252, Validation Loss: 0.0464\n",
      "Epoch 90/100, Train Loss: 0.0252, Validation Loss: 0.0464\n",
      "loss: 3.801660659377376 3.801660659377376\n",
      "Epoch 91/100, Train Loss: 0.0252, Validation Loss: 0.0464\n",
      "loss: 3.8015838991341298 3.8015838991341298\n",
      "Epoch 92/100, Train Loss: 0.0252, Validation Loss: 0.0465\n",
      "Epoch 93/100, Train Loss: 0.0252, Validation Loss: 0.0464\n",
      "Epoch 94/100, Train Loss: 0.0252, Validation Loss: 0.0464\n",
      "Epoch 95/100, Train Loss: 0.0251, Validation Loss: 0.0464\n",
      "Epoch 96/100, Train Loss: 0.0251, Validation Loss: 0.0464\n",
      "loss: 3.801161839852284 3.801161839852284\n",
      "Epoch 97/100, Train Loss: 0.0251, Validation Loss: 0.0463\n",
      "loss: 3.7937234659802925 3.7937234659802925\n",
      "Epoch 98/100, Train Loss: 0.0251, Validation Loss: 0.0463\n",
      "Epoch 99/100, Train Loss: 0.0250, Validation Loss: 0.0464\n",
      "Epoch 100/100, Train Loss: 0.0250, Validation Loss: 0.0464\n",
      "Fold 1 -> RMSE: 0.2151, MAE: 0.1558, R²: -0.0302\n",
      "\n",
      "Training Fold 2/10...\n",
      "Epoch 1/100, Train Loss: 0.0413, Validation Loss: 0.0270\n",
      "loss: 2.1903989944867135 2.1903989944867135\n",
      "Epoch 2/100, Train Loss: 0.0301, Validation Loss: 0.0268\n",
      "loss: 2.1727224628932618 2.1727224628932618\n",
      "Epoch 3/100, Train Loss: 0.0290, Validation Loss: 0.0272\n",
      "Epoch 4/100, Train Loss: 0.0286, Validation Loss: 0.0274\n",
      "Epoch 5/100, Train Loss: 0.0284, Validation Loss: 0.0275\n",
      "Epoch 6/100, Train Loss: 0.0282, Validation Loss: 0.0277\n",
      "Epoch 7/100, Train Loss: 0.0280, Validation Loss: 0.0279\n",
      "Epoch 8/100, Train Loss: 0.0279, Validation Loss: 0.0279\n",
      "Epoch 9/100, Train Loss: 0.0278, Validation Loss: 0.0281\n",
      "Epoch 10/100, Train Loss: 0.0277, Validation Loss: 0.0281\n",
      "Epoch 11/100, Train Loss: 0.0276, Validation Loss: 0.0282\n",
      "Epoch 12/100, Train Loss: 0.0275, Validation Loss: 0.0283\n",
      "Epoch 13/100, Train Loss: 0.0275, Validation Loss: 0.0283\n",
      "Epoch 00013: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 14/100, Train Loss: 0.0272, Validation Loss: 0.0281\n",
      "Epoch 15/100, Train Loss: 0.0271, Validation Loss: 0.0282\n",
      "Epoch 16/100, Train Loss: 0.0270, Validation Loss: 0.0282\n",
      "Epoch 17/100, Train Loss: 0.0270, Validation Loss: 0.0282\n",
      "Epoch 18/100, Train Loss: 0.0269, Validation Loss: 0.0283\n",
      "Epoch 19/100, Train Loss: 0.0269, Validation Loss: 0.0284\n",
      "Epoch 20/100, Train Loss: 0.0268, Validation Loss: 0.0283\n",
      "Epoch 21/100, Train Loss: 0.0267, Validation Loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 0.0267, Validation Loss: 0.0285\n",
      "Epoch 23/100, Train Loss: 0.0267, Validation Loss: 0.0284\n",
      "Epoch 24/100, Train Loss: 0.0266, Validation Loss: 0.0286\n",
      "Epoch 00024: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 25/100, Train Loss: 0.0264, Validation Loss: 0.0284\n",
      "Epoch 26/100, Train Loss: 0.0263, Validation Loss: 0.0283\n",
      "Epoch 27/100, Train Loss: 0.0262, Validation Loss: 0.0285\n",
      "Epoch 28/100, Train Loss: 0.0262, Validation Loss: 0.0285\n",
      "Epoch 29/100, Train Loss: 0.0262, Validation Loss: 0.0286\n",
      "Epoch 30/100, Train Loss: 0.0261, Validation Loss: 0.0285\n",
      "Epoch 31/100, Train Loss: 0.0261, Validation Loss: 0.0286\n",
      "Epoch 32/100, Train Loss: 0.0261, Validation Loss: 0.0286\n",
      "Epoch 33/100, Train Loss: 0.0260, Validation Loss: 0.0287\n",
      "Epoch 34/100, Train Loss: 0.0260, Validation Loss: 0.0287\n",
      "Epoch 35/100, Train Loss: 0.0260, Validation Loss: 0.0286\n",
      "Epoch 00035: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 36/100, Train Loss: 0.0258, Validation Loss: 0.0285\n",
      "Epoch 37/100, Train Loss: 0.0257, Validation Loss: 0.0285\n",
      "Epoch 38/100, Train Loss: 0.0257, Validation Loss: 0.0285\n",
      "Epoch 39/100, Train Loss: 0.0256, Validation Loss: 0.0286\n",
      "Epoch 40/100, Train Loss: 0.0256, Validation Loss: 0.0285\n",
      "Epoch 41/100, Train Loss: 0.0256, Validation Loss: 0.0286\n",
      "Epoch 42/100, Train Loss: 0.0256, Validation Loss: 0.0286\n",
      "Epoch 43/100, Train Loss: 0.0255, Validation Loss: 0.0287\n",
      "Epoch 44/100, Train Loss: 0.0256, Validation Loss: 0.0286\n",
      "Epoch 45/100, Train Loss: 0.0255, Validation Loss: 0.0287\n",
      "Epoch 46/100, Train Loss: 0.0255, Validation Loss: 0.0287\n",
      "Epoch 00046: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 47/100, Train Loss: 0.0253, Validation Loss: 0.0285\n",
      "Epoch 48/100, Train Loss: 0.0252, Validation Loss: 0.0286\n",
      "Epoch 49/100, Train Loss: 0.0252, Validation Loss: 0.0286\n",
      "Epoch 50/100, Train Loss: 0.0252, Validation Loss: 0.0287\n",
      "Epoch 51/100, Train Loss: 0.0252, Validation Loss: 0.0287\n",
      "Epoch 52/100, Train Loss: 0.0251, Validation Loss: 0.0287\n",
      "Epoch 53/100, Train Loss: 0.0251, Validation Loss: 0.0287\n",
      "Epoch 54/100, Train Loss: 0.0251, Validation Loss: 0.0287\n",
      "Epoch 55/100, Train Loss: 0.0251, Validation Loss: 0.0287\n",
      "Epoch 56/100, Train Loss: 0.0250, Validation Loss: 0.0287\n",
      "Epoch 57/100, Train Loss: 0.0251, Validation Loss: 0.0288\n",
      "Epoch 00057: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 58/100, Train Loss: 0.0249, Validation Loss: 0.0287\n",
      "Epoch 59/100, Train Loss: 0.0248, Validation Loss: 0.0287\n",
      "Epoch 60/100, Train Loss: 0.0248, Validation Loss: 0.0287\n",
      "Epoch 61/100, Train Loss: 0.0248, Validation Loss: 0.0287\n",
      "Epoch 62/100, Train Loss: 0.0247, Validation Loss: 0.0287\n",
      "Epoch 63/100, Train Loss: 0.0247, Validation Loss: 0.0287\n",
      "Epoch 64/100, Train Loss: 0.0247, Validation Loss: 0.0288\n",
      "Epoch 65/100, Train Loss: 0.0247, Validation Loss: 0.0287\n",
      "Epoch 66/100, Train Loss: 0.0247, Validation Loss: 0.0288\n",
      "Epoch 67/100, Train Loss: 0.0247, Validation Loss: 0.0287\n",
      "Epoch 68/100, Train Loss: 0.0247, Validation Loss: 0.0287\n",
      "Epoch 00068: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 69/100, Train Loss: 0.0245, Validation Loss: 0.0287\n",
      "Epoch 70/100, Train Loss: 0.0244, Validation Loss: 0.0287\n",
      "Epoch 71/100, Train Loss: 0.0245, Validation Loss: 0.0287\n",
      "Epoch 72/100, Train Loss: 0.0244, Validation Loss: 0.0287\n",
      "Epoch 73/100, Train Loss: 0.0244, Validation Loss: 0.0287\n",
      "Epoch 74/100, Train Loss: 0.0244, Validation Loss: 0.0287\n",
      "Epoch 75/100, Train Loss: 0.0244, Validation Loss: 0.0287\n",
      "Epoch 76/100, Train Loss: 0.0243, Validation Loss: 0.0288\n",
      "Epoch 77/100, Train Loss: 0.0244, Validation Loss: 0.0287\n",
      "Epoch 78/100, Train Loss: 0.0243, Validation Loss: 0.0287\n",
      "Epoch 79/100, Train Loss: 0.0243, Validation Loss: 0.0287\n",
      "Epoch 00079: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 80/100, Train Loss: 0.0242, Validation Loss: 0.0287\n",
      "Epoch 81/100, Train Loss: 0.0241, Validation Loss: 0.0287\n",
      "Epoch 82/100, Train Loss: 0.0241, Validation Loss: 0.0287\n",
      "Epoch 83/100, Train Loss: 0.0241, Validation Loss: 0.0287\n",
      "Epoch 84/100, Train Loss: 0.0241, Validation Loss: 0.0287\n",
      "Epoch 85/100, Train Loss: 0.0241, Validation Loss: 0.0287\n",
      "Epoch 86/100, Train Loss: 0.0240, Validation Loss: 0.0287\n",
      "Epoch 87/100, Train Loss: 0.0240, Validation Loss: 0.0287\n",
      "Epoch 88/100, Train Loss: 0.0240, Validation Loss: 0.0287\n",
      "Epoch 89/100, Train Loss: 0.0240, Validation Loss: 0.0287\n",
      "Epoch 90/100, Train Loss: 0.0240, Validation Loss: 0.0287\n",
      "Epoch 00090: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 91/100, Train Loss: 0.0239, Validation Loss: 0.0287\n",
      "Epoch 92/100, Train Loss: 0.0238, Validation Loss: 0.0287\n",
      "Epoch 93/100, Train Loss: 0.0238, Validation Loss: 0.0287\n",
      "Epoch 94/100, Train Loss: 0.0238, Validation Loss: 0.0287\n",
      "Epoch 95/100, Train Loss: 0.0238, Validation Loss: 0.0287\n",
      "Epoch 96/100, Train Loss: 0.0238, Validation Loss: 0.0287\n",
      "Epoch 97/100, Train Loss: 0.0237, Validation Loss: 0.0287\n",
      "Epoch 98/100, Train Loss: 0.0237, Validation Loss: 0.0287\n",
      "Epoch 99/100, Train Loss: 0.0237, Validation Loss: 0.0287\n",
      "Epoch 100/100, Train Loss: 0.0237, Validation Loss: 0.0287\n",
      "Fold 2 -> RMSE: 0.1638, MAE: 0.1106, R²: 0.3276\n",
      "\n",
      "Training Fold 3/10...\n",
      "Epoch 1/100, Train Loss: 0.0362, Validation Loss: 0.0203\n",
      "loss: 1.644144842364767 1.644144842364767\n",
      "Epoch 2/100, Train Loss: 0.0306, Validation Loss: 0.0199\n",
      "loss: 1.6083611373658186 1.6083611373658186\n",
      "Epoch 3/100, Train Loss: 0.0299, Validation Loss: 0.0197\n",
      "loss: 1.5923336246898998 1.5923336246898998\n",
      "Epoch 4/100, Train Loss: 0.0295, Validation Loss: 0.0197\n",
      "Epoch 5/100, Train Loss: 0.0292, Validation Loss: 0.0198\n",
      "Epoch 6/100, Train Loss: 0.0291, Validation Loss: 0.0197\n",
      "Epoch 7/100, Train Loss: 0.0289, Validation Loss: 0.0198\n",
      "Epoch 8/100, Train Loss: 0.0288, Validation Loss: 0.0197\n",
      "Epoch 9/100, Train Loss: 0.0287, Validation Loss: 0.0197\n",
      "Epoch 10/100, Train Loss: 0.0287, Validation Loss: 0.0197\n",
      "Epoch 11/100, Train Loss: 0.0286, Validation Loss: 0.0197\n",
      "Epoch 12/100, Train Loss: 0.0285, Validation Loss: 0.0197\n",
      "Epoch 13/100, Train Loss: 0.0285, Validation Loss: 0.0197\n",
      "Epoch 14/100, Train Loss: 0.0284, Validation Loss: 0.0197\n",
      "Epoch 00014: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 15/100, Train Loss: 0.0281, Validation Loss: 0.0193\n",
      "loss: 1.5629174402976105 1.5629174402976105\n",
      "Epoch 16/100, Train Loss: 0.0281, Validation Loss: 0.0193\n",
      "Epoch 17/100, Train Loss: 0.0280, Validation Loss: 0.0192\n",
      "loss: 1.5565444836056486 1.5565444836056486\n",
      "Epoch 18/100, Train Loss: 0.0279, Validation Loss: 0.0193\n",
      "Epoch 19/100, Train Loss: 0.0279, Validation Loss: 0.0192\n",
      "Epoch 20/100, Train Loss: 0.0278, Validation Loss: 0.0193\n",
      "Epoch 21/100, Train Loss: 0.0278, Validation Loss: 0.0193\n",
      "Epoch 22/100, Train Loss: 0.0277, Validation Loss: 0.0193\n",
      "Epoch 23/100, Train Loss: 0.0277, Validation Loss: 0.0193\n",
      "Epoch 24/100, Train Loss: 0.0277, Validation Loss: 0.0193\n",
      "Epoch 25/100, Train Loss: 0.0277, Validation Loss: 0.0194\n",
      "Epoch 26/100, Train Loss: 0.0276, Validation Loss: 0.0194\n",
      "Epoch 27/100, Train Loss: 0.0276, Validation Loss: 0.0194\n",
      "Epoch 28/100, Train Loss: 0.0275, Validation Loss: 0.0194\n",
      "Epoch 00028: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 29/100, Train Loss: 0.0273, Validation Loss: 0.0190\n",
      "loss: 1.5391903340478166 1.5391903340478166\n",
      "Epoch 30/100, Train Loss: 0.0273, Validation Loss: 0.0190\n",
      "loss: 1.5378524839998136 1.5378524839998136\n",
      "Epoch 31/100, Train Loss: 0.0272, Validation Loss: 0.0191\n",
      "Epoch 32/100, Train Loss: 0.0272, Validation Loss: 0.0190\n",
      "Epoch 33/100, Train Loss: 0.0272, Validation Loss: 0.0190\n",
      "Epoch 34/100, Train Loss: 0.0272, Validation Loss: 0.0190\n",
      "Epoch 35/100, Train Loss: 0.0271, Validation Loss: 0.0190\n",
      "Epoch 36/100, Train Loss: 0.0271, Validation Loss: 0.0191\n",
      "Epoch 37/100, Train Loss: 0.0271, Validation Loss: 0.0191\n",
      "Epoch 38/100, Train Loss: 0.0271, Validation Loss: 0.0191\n",
      "Epoch 39/100, Train Loss: 0.0270, Validation Loss: 0.0191\n",
      "Epoch 40/100, Train Loss: 0.0270, Validation Loss: 0.0191\n",
      "Epoch 41/100, Train Loss: 0.0270, Validation Loss: 0.0191\n",
      "Epoch 00041: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 42/100, Train Loss: 0.0268, Validation Loss: 0.0188\n",
      "loss: 1.5197695197284702 1.5197695197284702\n",
      "Epoch 43/100, Train Loss: 0.0268, Validation Loss: 0.0188\n",
      "Epoch 44/100, Train Loss: 0.0267, Validation Loss: 0.0188\n",
      "Epoch 45/100, Train Loss: 0.0267, Validation Loss: 0.0187\n",
      "loss: 1.517721517528571 1.517721517528571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 0.0267, Validation Loss: 0.0188\n",
      "Epoch 47/100, Train Loss: 0.0267, Validation Loss: 0.0188\n",
      "Epoch 48/100, Train Loss: 0.0266, Validation Loss: 0.0188\n",
      "Epoch 49/100, Train Loss: 0.0266, Validation Loss: 0.0188\n",
      "Epoch 50/100, Train Loss: 0.0266, Validation Loss: 0.0188\n",
      "Epoch 51/100, Train Loss: 0.0266, Validation Loss: 0.0188\n",
      "Epoch 52/100, Train Loss: 0.0265, Validation Loss: 0.0188\n",
      "Epoch 53/100, Train Loss: 0.0265, Validation Loss: 0.0189\n",
      "Epoch 54/100, Train Loss: 0.0265, Validation Loss: 0.0189\n",
      "Epoch 55/100, Train Loss: 0.0265, Validation Loss: 0.0189\n",
      "Epoch 56/100, Train Loss: 0.0265, Validation Loss: 0.0189\n",
      "Epoch 00056: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 57/100, Train Loss: 0.0263, Validation Loss: 0.0186\n",
      "loss: 1.50430243030587 1.50430243030587\n",
      "Epoch 58/100, Train Loss: 0.0263, Validation Loss: 0.0185\n",
      "loss: 1.4981851208858643 1.4981851208858643\n",
      "Epoch 59/100, Train Loss: 0.0263, Validation Loss: 0.0186\n",
      "Epoch 60/100, Train Loss: 0.0262, Validation Loss: 0.0186\n",
      "Epoch 61/100, Train Loss: 0.0262, Validation Loss: 0.0186\n",
      "Epoch 62/100, Train Loss: 0.0262, Validation Loss: 0.0186\n",
      "Epoch 63/100, Train Loss: 0.0262, Validation Loss: 0.0186\n",
      "Epoch 64/100, Train Loss: 0.0262, Validation Loss: 0.0185\n",
      "Epoch 65/100, Train Loss: 0.0262, Validation Loss: 0.0185\n",
      "Epoch 66/100, Train Loss: 0.0261, Validation Loss: 0.0186\n",
      "Epoch 67/100, Train Loss: 0.0261, Validation Loss: 0.0186\n",
      "Epoch 68/100, Train Loss: 0.0261, Validation Loss: 0.0186\n",
      "Epoch 69/100, Train Loss: 0.0261, Validation Loss: 0.0186\n",
      "Epoch 00069: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 70/100, Train Loss: 0.0259, Validation Loss: 0.0183\n",
      "loss: 1.481207225532728 1.481207225532728\n",
      "Epoch 71/100, Train Loss: 0.0259, Validation Loss: 0.0183\n",
      "Epoch 72/100, Train Loss: 0.0259, Validation Loss: 0.0183\n",
      "Epoch 73/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "loss: 1.4809010471155126 1.4809010471155126\n",
      "Epoch 74/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "Epoch 75/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "loss: 1.4792579490260778 1.4792579490260778\n",
      "Epoch 76/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "Epoch 77/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "Epoch 78/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "Epoch 79/100, Train Loss: 0.0257, Validation Loss: 0.0183\n",
      "Epoch 80/100, Train Loss: 0.0258, Validation Loss: 0.0183\n",
      "loss: 1.4790857521438738 1.4790857521438738\n",
      "Epoch 81/100, Train Loss: 0.0257, Validation Loss: 0.0183\n",
      "Epoch 82/100, Train Loss: 0.0257, Validation Loss: 0.0184\n",
      "Epoch 83/100, Train Loss: 0.0257, Validation Loss: 0.0183\n",
      "Epoch 84/100, Train Loss: 0.0257, Validation Loss: 0.0184\n",
      "Epoch 85/100, Train Loss: 0.0257, Validation Loss: 0.0183\n",
      "Epoch 86/100, Train Loss: 0.0256, Validation Loss: 0.0183\n",
      "Epoch 87/100, Train Loss: 0.0256, Validation Loss: 0.0183\n",
      "Epoch 88/100, Train Loss: 0.0256, Validation Loss: 0.0184\n",
      "Epoch 89/100, Train Loss: 0.0256, Validation Loss: 0.0183\n",
      "Epoch 90/100, Train Loss: 0.0256, Validation Loss: 0.0184\n",
      "Epoch 91/100, Train Loss: 0.0256, Validation Loss: 0.0184\n",
      "Epoch 00091: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 92/100, Train Loss: 0.0255, Validation Loss: 0.0181\n",
      "loss: 1.463164339233117 1.463164339233117\n",
      "Epoch 93/100, Train Loss: 0.0254, Validation Loss: 0.0181\n",
      "Epoch 94/100, Train Loss: 0.0254, Validation Loss: 0.0181\n",
      "Epoch 95/100, Train Loss: 0.0254, Validation Loss: 0.0181\n",
      "Epoch 96/100, Train Loss: 0.0254, Validation Loss: 0.0181\n",
      "Epoch 97/100, Train Loss: 0.0254, Validation Loss: 0.0181\n",
      "Epoch 98/100, Train Loss: 0.0253, Validation Loss: 0.0181\n",
      "Epoch 99/100, Train Loss: 0.0253, Validation Loss: 0.0181\n",
      "Epoch 100/100, Train Loss: 0.0253, Validation Loss: 0.0181\n",
      "Fold 3 -> RMSE: 0.1344, MAE: 0.1035, R²: 0.5162\n",
      "\n",
      "Training Fold 4/10...\n",
      "Epoch 1/100, Train Loss: 0.0355, Validation Loss: 0.0223\n",
      "loss: 1.8054047365497468 1.8054047365497468\n",
      "Epoch 2/100, Train Loss: 0.0274, Validation Loss: 0.0234\n",
      "Epoch 3/100, Train Loss: 0.0266, Validation Loss: 0.0237\n",
      "Epoch 4/100, Train Loss: 0.0263, Validation Loss: 0.0239\n",
      "Epoch 5/100, Train Loss: 0.0261, Validation Loss: 0.0240\n",
      "Epoch 6/100, Train Loss: 0.0260, Validation Loss: 0.0242\n",
      "Epoch 7/100, Train Loss: 0.0259, Validation Loss: 0.0242\n",
      "Epoch 8/100, Train Loss: 0.0258, Validation Loss: 0.0242\n",
      "Epoch 9/100, Train Loss: 0.0258, Validation Loss: 0.0245\n",
      "Epoch 10/100, Train Loss: 0.0257, Validation Loss: 0.0245\n",
      "Epoch 11/100, Train Loss: 0.0257, Validation Loss: 0.0245\n",
      "Epoch 12/100, Train Loss: 0.0256, Validation Loss: 0.0247\n",
      "Epoch 00012: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 13/100, Train Loss: 0.0253, Validation Loss: 0.0245\n",
      "Epoch 14/100, Train Loss: 0.0253, Validation Loss: 0.0245\n",
      "Epoch 15/100, Train Loss: 0.0252, Validation Loss: 0.0246\n",
      "Epoch 16/100, Train Loss: 0.0251, Validation Loss: 0.0246\n",
      "Epoch 17/100, Train Loss: 0.0251, Validation Loss: 0.0246\n",
      "Epoch 18/100, Train Loss: 0.0251, Validation Loss: 0.0248\n",
      "Epoch 19/100, Train Loss: 0.0250, Validation Loss: 0.0248\n",
      "Epoch 20/100, Train Loss: 0.0250, Validation Loss: 0.0248\n",
      "Epoch 21/100, Train Loss: 0.0249, Validation Loss: 0.0249\n",
      "Epoch 22/100, Train Loss: 0.0249, Validation Loss: 0.0249\n",
      "Epoch 23/100, Train Loss: 0.0249, Validation Loss: 0.0250\n",
      "Epoch 00023: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 24/100, Train Loss: 0.0247, Validation Loss: 0.0248\n",
      "Epoch 25/100, Train Loss: 0.0246, Validation Loss: 0.0249\n",
      "Epoch 26/100, Train Loss: 0.0246, Validation Loss: 0.0249\n",
      "Epoch 27/100, Train Loss: 0.0245, Validation Loss: 0.0248\n",
      "Epoch 28/100, Train Loss: 0.0245, Validation Loss: 0.0250\n",
      "Epoch 29/100, Train Loss: 0.0245, Validation Loss: 0.0249\n",
      "Epoch 30/100, Train Loss: 0.0244, Validation Loss: 0.0250\n",
      "Epoch 31/100, Train Loss: 0.0244, Validation Loss: 0.0251\n",
      "Epoch 32/100, Train Loss: 0.0243, Validation Loss: 0.0251\n",
      "Epoch 33/100, Train Loss: 0.0243, Validation Loss: 0.0252\n",
      "Epoch 34/100, Train Loss: 0.0243, Validation Loss: 0.0251\n",
      "Epoch 00034: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 35/100, Train Loss: 0.0241, Validation Loss: 0.0250\n",
      "Epoch 36/100, Train Loss: 0.0240, Validation Loss: 0.0250\n",
      "Epoch 37/100, Train Loss: 0.0240, Validation Loss: 0.0250\n",
      "Epoch 38/100, Train Loss: 0.0240, Validation Loss: 0.0251\n",
      "Epoch 39/100, Train Loss: 0.0240, Validation Loss: 0.0252\n",
      "Epoch 40/100, Train Loss: 0.0239, Validation Loss: 0.0252\n",
      "Epoch 41/100, Train Loss: 0.0239, Validation Loss: 0.0252\n",
      "Epoch 42/100, Train Loss: 0.0238, Validation Loss: 0.0252\n",
      "Epoch 43/100, Train Loss: 0.0238, Validation Loss: 0.0254\n",
      "Epoch 44/100, Train Loss: 0.0238, Validation Loss: 0.0253\n",
      "Epoch 45/100, Train Loss: 0.0237, Validation Loss: 0.0253\n",
      "Epoch 00045: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 46/100, Train Loss: 0.0236, Validation Loss: 0.0252\n",
      "Epoch 47/100, Train Loss: 0.0235, Validation Loss: 0.0253\n",
      "Epoch 48/100, Train Loss: 0.0235, Validation Loss: 0.0253\n",
      "Epoch 49/100, Train Loss: 0.0234, Validation Loss: 0.0254\n",
      "Epoch 50/100, Train Loss: 0.0234, Validation Loss: 0.0254\n",
      "Epoch 51/100, Train Loss: 0.0234, Validation Loss: 0.0254\n",
      "Epoch 52/100, Train Loss: 0.0234, Validation Loss: 0.0254\n",
      "Epoch 53/100, Train Loss: 0.0233, Validation Loss: 0.0254\n",
      "Epoch 54/100, Train Loss: 0.0233, Validation Loss: 0.0255\n",
      "Epoch 55/100, Train Loss: 0.0233, Validation Loss: 0.0255\n",
      "Epoch 56/100, Train Loss: 0.0233, Validation Loss: 0.0256\n",
      "Epoch 00056: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 57/100, Train Loss: 0.0231, Validation Loss: 0.0254\n",
      "Epoch 58/100, Train Loss: 0.0231, Validation Loss: 0.0255\n",
      "Epoch 59/100, Train Loss: 0.0230, Validation Loss: 0.0254\n",
      "Epoch 60/100, Train Loss: 0.0230, Validation Loss: 0.0255\n",
      "Epoch 61/100, Train Loss: 0.0230, Validation Loss: 0.0255\n",
      "Epoch 62/100, Train Loss: 0.0229, Validation Loss: 0.0256\n",
      "Epoch 63/100, Train Loss: 0.0229, Validation Loss: 0.0256\n",
      "Epoch 64/100, Train Loss: 0.0229, Validation Loss: 0.0256\n",
      "Epoch 65/100, Train Loss: 0.0229, Validation Loss: 0.0257\n",
      "Epoch 66/100, Train Loss: 0.0229, Validation Loss: 0.0257\n",
      "Epoch 67/100, Train Loss: 0.0228, Validation Loss: 0.0257\n",
      "Epoch 00067: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 68/100, Train Loss: 0.0227, Validation Loss: 0.0256\n",
      "Epoch 69/100, Train Loss: 0.0226, Validation Loss: 0.0257\n",
      "Epoch 70/100, Train Loss: 0.0226, Validation Loss: 0.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 0.0225, Validation Loss: 0.0257\n",
      "Epoch 72/100, Train Loss: 0.0225, Validation Loss: 0.0257\n",
      "Epoch 73/100, Train Loss: 0.0225, Validation Loss: 0.0257\n",
      "Epoch 74/100, Train Loss: 0.0225, Validation Loss: 0.0259\n",
      "Epoch 75/100, Train Loss: 0.0224, Validation Loss: 0.0258\n",
      "Epoch 76/100, Train Loss: 0.0225, Validation Loss: 0.0259\n",
      "Epoch 77/100, Train Loss: 0.0224, Validation Loss: 0.0257\n",
      "Epoch 78/100, Train Loss: 0.0224, Validation Loss: 0.0258\n",
      "Epoch 00078: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 79/100, Train Loss: 0.0223, Validation Loss: 0.0257\n",
      "Epoch 80/100, Train Loss: 0.0222, Validation Loss: 0.0258\n",
      "Epoch 81/100, Train Loss: 0.0222, Validation Loss: 0.0259\n",
      "Epoch 82/100, Train Loss: 0.0222, Validation Loss: 0.0258\n",
      "Epoch 83/100, Train Loss: 0.0222, Validation Loss: 0.0259\n",
      "Epoch 84/100, Train Loss: 0.0221, Validation Loss: 0.0258\n",
      "Epoch 85/100, Train Loss: 0.0221, Validation Loss: 0.0260\n",
      "Epoch 86/100, Train Loss: 0.0221, Validation Loss: 0.0259\n",
      "Epoch 87/100, Train Loss: 0.0221, Validation Loss: 0.0260\n",
      "Epoch 88/100, Train Loss: 0.0220, Validation Loss: 0.0260\n",
      "Epoch 89/100, Train Loss: 0.0220, Validation Loss: 0.0261\n",
      "Epoch 00089: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 90/100, Train Loss: 0.0219, Validation Loss: 0.0260\n",
      "Epoch 91/100, Train Loss: 0.0218, Validation Loss: 0.0259\n",
      "Epoch 92/100, Train Loss: 0.0219, Validation Loss: 0.0260\n",
      "Epoch 93/100, Train Loss: 0.0218, Validation Loss: 0.0260\n",
      "Epoch 94/100, Train Loss: 0.0218, Validation Loss: 0.0260\n",
      "Epoch 95/100, Train Loss: 0.0218, Validation Loss: 0.0261\n",
      "Epoch 96/100, Train Loss: 0.0217, Validation Loss: 0.0260\n",
      "Epoch 97/100, Train Loss: 0.0218, Validation Loss: 0.0261\n",
      "Epoch 98/100, Train Loss: 0.0217, Validation Loss: 0.0261\n",
      "Epoch 99/100, Train Loss: 0.0217, Validation Loss: 0.0261\n",
      "Epoch 100/100, Train Loss: 0.0217, Validation Loss: 0.0262\n",
      "Epoch 00100: reducing learning rate of group 0 to 3.8742e-04.\n",
      "Fold 4 -> RMSE: 0.1493, MAE: 0.1177, R²: 0.3286\n",
      "\n",
      "Training Fold 5/10...\n",
      "Epoch 1/100, Train Loss: 0.0327, Validation Loss: 0.0322\n",
      "loss: 2.612186444204781 2.612186444204781\n",
      "Epoch 2/100, Train Loss: 0.0273, Validation Loss: 0.0343\n",
      "Epoch 3/100, Train Loss: 0.0264, Validation Loss: 0.0350\n",
      "Epoch 4/100, Train Loss: 0.0260, Validation Loss: 0.0354\n",
      "Epoch 5/100, Train Loss: 0.0258, Validation Loss: 0.0357\n",
      "Epoch 6/100, Train Loss: 0.0257, Validation Loss: 0.0360\n",
      "Epoch 7/100, Train Loss: 0.0256, Validation Loss: 0.0361\n",
      "Epoch 8/100, Train Loss: 0.0255, Validation Loss: 0.0362\n",
      "Epoch 9/100, Train Loss: 0.0255, Validation Loss: 0.0363\n",
      "Epoch 10/100, Train Loss: 0.0254, Validation Loss: 0.0362\n",
      "Epoch 11/100, Train Loss: 0.0254, Validation Loss: 0.0364\n",
      "Epoch 12/100, Train Loss: 0.0253, Validation Loss: 0.0364\n",
      "Epoch 00012: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 13/100, Train Loss: 0.0250, Validation Loss: 0.0359\n",
      "Epoch 14/100, Train Loss: 0.0250, Validation Loss: 0.0359\n",
      "Epoch 15/100, Train Loss: 0.0250, Validation Loss: 0.0358\n",
      "Epoch 16/100, Train Loss: 0.0249, Validation Loss: 0.0360\n",
      "Epoch 17/100, Train Loss: 0.0249, Validation Loss: 0.0360\n",
      "Epoch 18/100, Train Loss: 0.0248, Validation Loss: 0.0362\n",
      "Epoch 19/100, Train Loss: 0.0248, Validation Loss: 0.0359\n",
      "Epoch 20/100, Train Loss: 0.0248, Validation Loss: 0.0361\n",
      "Epoch 21/100, Train Loss: 0.0248, Validation Loss: 0.0360\n",
      "Epoch 22/100, Train Loss: 0.0248, Validation Loss: 0.0360\n",
      "Epoch 23/100, Train Loss: 0.0247, Validation Loss: 0.0362\n",
      "Epoch 00023: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 24/100, Train Loss: 0.0245, Validation Loss: 0.0357\n",
      "Epoch 25/100, Train Loss: 0.0244, Validation Loss: 0.0358\n",
      "Epoch 26/100, Train Loss: 0.0244, Validation Loss: 0.0358\n",
      "Epoch 27/100, Train Loss: 0.0244, Validation Loss: 0.0357\n",
      "Epoch 28/100, Train Loss: 0.0244, Validation Loss: 0.0358\n",
      "Epoch 29/100, Train Loss: 0.0243, Validation Loss: 0.0357\n",
      "Epoch 30/100, Train Loss: 0.0243, Validation Loss: 0.0358\n",
      "Epoch 31/100, Train Loss: 0.0243, Validation Loss: 0.0360\n",
      "Epoch 32/100, Train Loss: 0.0243, Validation Loss: 0.0358\n",
      "Epoch 33/100, Train Loss: 0.0242, Validation Loss: 0.0359\n",
      "Epoch 34/100, Train Loss: 0.0243, Validation Loss: 0.0360\n",
      "Epoch 00034: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 35/100, Train Loss: 0.0240, Validation Loss: 0.0353\n",
      "Epoch 36/100, Train Loss: 0.0240, Validation Loss: 0.0354\n",
      "Epoch 37/100, Train Loss: 0.0239, Validation Loss: 0.0355\n",
      "Epoch 38/100, Train Loss: 0.0239, Validation Loss: 0.0354\n",
      "Epoch 39/100, Train Loss: 0.0239, Validation Loss: 0.0355\n",
      "Epoch 40/100, Train Loss: 0.0239, Validation Loss: 0.0355\n",
      "Epoch 41/100, Train Loss: 0.0239, Validation Loss: 0.0354\n",
      "Epoch 42/100, Train Loss: 0.0239, Validation Loss: 0.0355\n",
      "Epoch 43/100, Train Loss: 0.0239, Validation Loss: 0.0355\n",
      "Epoch 44/100, Train Loss: 0.0238, Validation Loss: 0.0355\n",
      "Epoch 45/100, Train Loss: 0.0239, Validation Loss: 0.0356\n",
      "Epoch 00045: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 46/100, Train Loss: 0.0236, Validation Loss: 0.0351\n",
      "Epoch 47/100, Train Loss: 0.0236, Validation Loss: 0.0352\n",
      "Epoch 48/100, Train Loss: 0.0236, Validation Loss: 0.0351\n",
      "Epoch 49/100, Train Loss: 0.0236, Validation Loss: 0.0352\n",
      "Epoch 50/100, Train Loss: 0.0235, Validation Loss: 0.0352\n",
      "Epoch 51/100, Train Loss: 0.0236, Validation Loss: 0.0352\n",
      "Epoch 52/100, Train Loss: 0.0235, Validation Loss: 0.0352\n",
      "Epoch 53/100, Train Loss: 0.0235, Validation Loss: 0.0353\n",
      "Epoch 54/100, Train Loss: 0.0235, Validation Loss: 0.0353\n",
      "Epoch 55/100, Train Loss: 0.0235, Validation Loss: 0.0352\n",
      "Epoch 56/100, Train Loss: 0.0235, Validation Loss: 0.0353\n",
      "Epoch 00056: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 57/100, Train Loss: 0.0233, Validation Loss: 0.0349\n",
      "Epoch 58/100, Train Loss: 0.0233, Validation Loss: 0.0349\n",
      "Epoch 59/100, Train Loss: 0.0232, Validation Loss: 0.0349\n",
      "Epoch 60/100, Train Loss: 0.0232, Validation Loss: 0.0349\n",
      "Epoch 61/100, Train Loss: 0.0232, Validation Loss: 0.0349\n",
      "Epoch 62/100, Train Loss: 0.0232, Validation Loss: 0.0349\n",
      "Epoch 63/100, Train Loss: 0.0232, Validation Loss: 0.0350\n",
      "Epoch 64/100, Train Loss: 0.0232, Validation Loss: 0.0349\n",
      "Epoch 65/100, Train Loss: 0.0231, Validation Loss: 0.0350\n",
      "Epoch 66/100, Train Loss: 0.0232, Validation Loss: 0.0349\n",
      "Epoch 67/100, Train Loss: 0.0231, Validation Loss: 0.0350\n",
      "Epoch 00067: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 68/100, Train Loss: 0.0230, Validation Loss: 0.0347\n",
      "Epoch 69/100, Train Loss: 0.0229, Validation Loss: 0.0347\n",
      "Epoch 70/100, Train Loss: 0.0229, Validation Loss: 0.0346\n",
      "Epoch 71/100, Train Loss: 0.0229, Validation Loss: 0.0346\n",
      "Epoch 72/100, Train Loss: 0.0229, Validation Loss: 0.0347\n",
      "Epoch 73/100, Train Loss: 0.0229, Validation Loss: 0.0347\n",
      "Epoch 74/100, Train Loss: 0.0229, Validation Loss: 0.0347\n",
      "Epoch 75/100, Train Loss: 0.0229, Validation Loss: 0.0347\n",
      "Epoch 76/100, Train Loss: 0.0228, Validation Loss: 0.0347\n",
      "Epoch 77/100, Train Loss: 0.0228, Validation Loss: 0.0348\n",
      "Epoch 78/100, Train Loss: 0.0228, Validation Loss: 0.0348\n",
      "Epoch 00078: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 79/100, Train Loss: 0.0227, Validation Loss: 0.0344\n",
      "Epoch 80/100, Train Loss: 0.0227, Validation Loss: 0.0345\n",
      "Epoch 81/100, Train Loss: 0.0226, Validation Loss: 0.0345\n",
      "Epoch 82/100, Train Loss: 0.0226, Validation Loss: 0.0345\n",
      "Epoch 83/100, Train Loss: 0.0226, Validation Loss: 0.0344\n",
      "Epoch 84/100, Train Loss: 0.0226, Validation Loss: 0.0345\n",
      "Epoch 85/100, Train Loss: 0.0226, Validation Loss: 0.0344\n",
      "Epoch 86/100, Train Loss: 0.0225, Validation Loss: 0.0345\n",
      "Epoch 87/100, Train Loss: 0.0226, Validation Loss: 0.0345\n",
      "Epoch 88/100, Train Loss: 0.0225, Validation Loss: 0.0345\n",
      "Epoch 89/100, Train Loss: 0.0225, Validation Loss: 0.0345\n",
      "Epoch 00089: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 90/100, Train Loss: 0.0224, Validation Loss: 0.0342\n",
      "Epoch 91/100, Train Loss: 0.0224, Validation Loss: 0.0342\n",
      "Epoch 92/100, Train Loss: 0.0224, Validation Loss: 0.0343\n",
      "Epoch 93/100, Train Loss: 0.0223, Validation Loss: 0.0343\n",
      "Epoch 94/100, Train Loss: 0.0223, Validation Loss: 0.0343\n",
      "Epoch 95/100, Train Loss: 0.0223, Validation Loss: 0.0343\n",
      "Epoch 96/100, Train Loss: 0.0223, Validation Loss: 0.0341\n",
      "Epoch 97/100, Train Loss: 0.0223, Validation Loss: 0.0342\n",
      "Epoch 98/100, Train Loss: 0.0223, Validation Loss: 0.0342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 0.0223, Validation Loss: 0.0343\n",
      "Epoch 100/100, Train Loss: 0.0223, Validation Loss: 0.0342\n",
      "Epoch 00100: reducing learning rate of group 0 to 3.8742e-04.\n",
      "Fold 5 -> RMSE: 0.1796, MAE: 0.1368, R²: 0.2473\n",
      "\n",
      "Training Fold 6/10...\n",
      "Epoch 1/100, Train Loss: 0.0338, Validation Loss: 0.0318\n",
      "loss: 2.57869861665381 2.57869861665381\n",
      "Epoch 2/100, Train Loss: 0.0282, Validation Loss: 0.0299\n",
      "loss: 2.4191563483070126 2.4191563483070126\n",
      "Epoch 3/100, Train Loss: 0.0272, Validation Loss: 0.0295\n",
      "loss: 2.389916504481878 2.389916504481878\n",
      "Epoch 4/100, Train Loss: 0.0268, Validation Loss: 0.0293\n",
      "loss: 2.3772436027252297 2.3772436027252297\n",
      "Epoch 5/100, Train Loss: 0.0265, Validation Loss: 0.0293\n",
      "loss: 2.3765173854501427 2.3765173854501427\n",
      "Epoch 6/100, Train Loss: 0.0264, Validation Loss: 0.0294\n",
      "Epoch 7/100, Train Loss: 0.0263, Validation Loss: 0.0295\n",
      "Epoch 8/100, Train Loss: 0.0262, Validation Loss: 0.0295\n",
      "Epoch 9/100, Train Loss: 0.0261, Validation Loss: 0.0294\n",
      "Epoch 10/100, Train Loss: 0.0260, Validation Loss: 0.0295\n",
      "Epoch 11/100, Train Loss: 0.0260, Validation Loss: 0.0295\n",
      "Epoch 12/100, Train Loss: 0.0259, Validation Loss: 0.0294\n",
      "Epoch 13/100, Train Loss: 0.0259, Validation Loss: 0.0295\n",
      "Epoch 14/100, Train Loss: 0.0258, Validation Loss: 0.0296\n",
      "Epoch 15/100, Train Loss: 0.0258, Validation Loss: 0.0296\n",
      "Epoch 16/100, Train Loss: 0.0258, Validation Loss: 0.0297\n",
      "Epoch 00016: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 17/100, Train Loss: 0.0256, Validation Loss: 0.0289\n",
      "loss: 2.3416735657701793 2.3416735657701793\n",
      "Epoch 18/100, Train Loss: 0.0255, Validation Loss: 0.0290\n",
      "Epoch 19/100, Train Loss: 0.0255, Validation Loss: 0.0290\n",
      "Epoch 20/100, Train Loss: 0.0254, Validation Loss: 0.0290\n",
      "Epoch 21/100, Train Loss: 0.0254, Validation Loss: 0.0289\n",
      "Epoch 22/100, Train Loss: 0.0253, Validation Loss: 0.0289\n",
      "Epoch 23/100, Train Loss: 0.0253, Validation Loss: 0.0289\n",
      "Epoch 24/100, Train Loss: 0.0253, Validation Loss: 0.0290\n",
      "Epoch 25/100, Train Loss: 0.0253, Validation Loss: 0.0290\n",
      "Epoch 26/100, Train Loss: 0.0252, Validation Loss: 0.0290\n",
      "Epoch 27/100, Train Loss: 0.0252, Validation Loss: 0.0290\n",
      "Epoch 28/100, Train Loss: 0.0252, Validation Loss: 0.0292\n",
      "Epoch 00028: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 29/100, Train Loss: 0.0251, Validation Loss: 0.0283\n",
      "loss: 2.2931831320220226 2.2931831320220226\n",
      "Epoch 30/100, Train Loss: 0.0250, Validation Loss: 0.0284\n",
      "Epoch 31/100, Train Loss: 0.0250, Validation Loss: 0.0283\n",
      "Epoch 32/100, Train Loss: 0.0249, Validation Loss: 0.0283\n",
      "Epoch 33/100, Train Loss: 0.0249, Validation Loss: 0.0283\n",
      "Epoch 34/100, Train Loss: 0.0248, Validation Loss: 0.0284\n",
      "Epoch 35/100, Train Loss: 0.0249, Validation Loss: 0.0284\n",
      "Epoch 36/100, Train Loss: 0.0248, Validation Loss: 0.0284\n",
      "Epoch 37/100, Train Loss: 0.0248, Validation Loss: 0.0285\n",
      "Epoch 38/100, Train Loss: 0.0248, Validation Loss: 0.0285\n",
      "Epoch 39/100, Train Loss: 0.0248, Validation Loss: 0.0286\n",
      "Epoch 40/100, Train Loss: 0.0247, Validation Loss: 0.0287\n",
      "Epoch 00040: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 41/100, Train Loss: 0.0246, Validation Loss: 0.0279\n",
      "loss: 2.2608383262304983 2.2608383262304983\n",
      "Epoch 42/100, Train Loss: 0.0245, Validation Loss: 0.0279\n",
      "Epoch 43/100, Train Loss: 0.0245, Validation Loss: 0.0280\n",
      "Epoch 44/100, Train Loss: 0.0245, Validation Loss: 0.0280\n",
      "Epoch 45/100, Train Loss: 0.0244, Validation Loss: 0.0279\n",
      "Epoch 46/100, Train Loss: 0.0245, Validation Loss: 0.0280\n",
      "Epoch 47/100, Train Loss: 0.0244, Validation Loss: 0.0279\n",
      "loss: 2.2586465164021092 2.2586465164021092\n",
      "Epoch 48/100, Train Loss: 0.0244, Validation Loss: 0.0280\n",
      "Epoch 49/100, Train Loss: 0.0244, Validation Loss: 0.0280\n",
      "Epoch 50/100, Train Loss: 0.0243, Validation Loss: 0.0280\n",
      "Epoch 51/100, Train Loss: 0.0244, Validation Loss: 0.0280\n",
      "Epoch 52/100, Train Loss: 0.0243, Validation Loss: 0.0280\n",
      "Epoch 53/100, Train Loss: 0.0243, Validation Loss: 0.0281\n",
      "Epoch 54/100, Train Loss: 0.0243, Validation Loss: 0.0280\n",
      "Epoch 55/100, Train Loss: 0.0243, Validation Loss: 0.0280\n",
      "Epoch 56/100, Train Loss: 0.0242, Validation Loss: 0.0281\n",
      "Epoch 57/100, Train Loss: 0.0242, Validation Loss: 0.0280\n",
      "Epoch 58/100, Train Loss: 0.0242, Validation Loss: 0.0281\n",
      "Epoch 00058: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 59/100, Train Loss: 0.0241, Validation Loss: 0.0274\n",
      "loss: 2.2192864813223423 2.2192864813223423\n",
      "Epoch 60/100, Train Loss: 0.0240, Validation Loss: 0.0274\n",
      "loss: 2.218208078373209 2.218208078373209\n",
      "Epoch 61/100, Train Loss: 0.0240, Validation Loss: 0.0275\n",
      "Epoch 62/100, Train Loss: 0.0240, Validation Loss: 0.0274\n",
      "Epoch 63/100, Train Loss: 0.0239, Validation Loss: 0.0275\n",
      "Epoch 64/100, Train Loss: 0.0240, Validation Loss: 0.0275\n",
      "Epoch 65/100, Train Loss: 0.0239, Validation Loss: 0.0275\n",
      "Epoch 66/100, Train Loss: 0.0239, Validation Loss: 0.0274\n",
      "Epoch 67/100, Train Loss: 0.0239, Validation Loss: 0.0275\n",
      "Epoch 68/100, Train Loss: 0.0239, Validation Loss: 0.0275\n",
      "Epoch 69/100, Train Loss: 0.0238, Validation Loss: 0.0276\n",
      "Epoch 70/100, Train Loss: 0.0238, Validation Loss: 0.0275\n",
      "Epoch 71/100, Train Loss: 0.0238, Validation Loss: 0.0275\n",
      "Epoch 00071: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 72/100, Train Loss: 0.0237, Validation Loss: 0.0270\n",
      "loss: 2.1899340662041595 2.1899340662041595\n",
      "Epoch 73/100, Train Loss: 0.0236, Validation Loss: 0.0270\n",
      "loss: 2.18418095520866 2.18418095520866\n",
      "Epoch 74/100, Train Loss: 0.0236, Validation Loss: 0.0269\n",
      "loss: 2.181760694552011 2.181760694552011\n",
      "Epoch 75/100, Train Loss: 0.0236, Validation Loss: 0.0269\n",
      "loss: 2.1805691761962294 2.1805691761962294\n",
      "Epoch 76/100, Train Loss: 0.0236, Validation Loss: 0.0269\n",
      "Epoch 77/100, Train Loss: 0.0236, Validation Loss: 0.0270\n",
      "Epoch 78/100, Train Loss: 0.0235, Validation Loss: 0.0270\n",
      "Epoch 79/100, Train Loss: 0.0235, Validation Loss: 0.0270\n",
      "Epoch 80/100, Train Loss: 0.0235, Validation Loss: 0.0270\n",
      "Epoch 81/100, Train Loss: 0.0235, Validation Loss: 0.0269\n",
      "Epoch 82/100, Train Loss: 0.0235, Validation Loss: 0.0270\n",
      "Epoch 83/100, Train Loss: 0.0235, Validation Loss: 0.0270\n",
      "Epoch 84/100, Train Loss: 0.0234, Validation Loss: 0.0270\n",
      "Epoch 85/100, Train Loss: 0.0234, Validation Loss: 0.0270\n",
      "Epoch 86/100, Train Loss: 0.0234, Validation Loss: 0.0270\n",
      "Epoch 00086: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 87/100, Train Loss: 0.0233, Validation Loss: 0.0265\n",
      "loss: 2.1445795525195592 2.1445795525195592\n",
      "Epoch 88/100, Train Loss: 0.0233, Validation Loss: 0.0265\n",
      "Epoch 89/100, Train Loss: 0.0232, Validation Loss: 0.0266\n",
      "Epoch 90/100, Train Loss: 0.0232, Validation Loss: 0.0265\n",
      "loss: 2.142825424498369 2.142825424498369\n",
      "Epoch 91/100, Train Loss: 0.0232, Validation Loss: 0.0265\n",
      "Epoch 92/100, Train Loss: 0.0232, Validation Loss: 0.0265\n",
      "Epoch 93/100, Train Loss: 0.0232, Validation Loss: 0.0264\n",
      "loss: 2.14093388744368 2.14093388744368\n",
      "Epoch 94/100, Train Loss: 0.0232, Validation Loss: 0.0264\n",
      "Epoch 95/100, Train Loss: 0.0232, Validation Loss: 0.0265\n",
      "Epoch 96/100, Train Loss: 0.0232, Validation Loss: 0.0264\n",
      "Epoch 97/100, Train Loss: 0.0231, Validation Loss: 0.0265\n",
      "Epoch 98/100, Train Loss: 0.0231, Validation Loss: 0.0264\n",
      "loss: 2.140497325127626 2.140497325127626\n",
      "Epoch 99/100, Train Loss: 0.0231, Validation Loss: 0.0264\n",
      "Epoch 100/100, Train Loss: 0.0231, Validation Loss: 0.0266\n",
      "Fold 6 -> RMSE: 0.1626, MAE: 0.1287, R²: 0.4758\n",
      "\n",
      "Training Fold 7/10...\n",
      "Epoch 1/100, Train Loss: 0.0352, Validation Loss: 0.0243\n",
      "loss: 1.965422177997425 1.965422177997425\n",
      "Epoch 2/100, Train Loss: 0.0269, Validation Loss: 0.0268\n",
      "Epoch 3/100, Train Loss: 0.0260, Validation Loss: 0.0275\n",
      "Epoch 4/100, Train Loss: 0.0257, Validation Loss: 0.0280\n",
      "Epoch 5/100, Train Loss: 0.0256, Validation Loss: 0.0282\n",
      "Epoch 6/100, Train Loss: 0.0255, Validation Loss: 0.0282\n",
      "Epoch 7/100, Train Loss: 0.0253, Validation Loss: 0.0285\n",
      "Epoch 8/100, Train Loss: 0.0253, Validation Loss: 0.0285\n",
      "Epoch 9/100, Train Loss: 0.0252, Validation Loss: 0.0286\n",
      "Epoch 10/100, Train Loss: 0.0251, Validation Loss: 0.0287\n",
      "Epoch 11/100, Train Loss: 0.0250, Validation Loss: 0.0289\n",
      "Epoch 12/100, Train Loss: 0.0250, Validation Loss: 0.0289\n",
      "Epoch 00012: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 13/100, Train Loss: 0.0247, Validation Loss: 0.0280\n",
      "Epoch 14/100, Train Loss: 0.0246, Validation Loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 0.0246, Validation Loss: 0.0282\n",
      "Epoch 16/100, Train Loss: 0.0245, Validation Loss: 0.0282\n",
      "Epoch 17/100, Train Loss: 0.0244, Validation Loss: 0.0283\n",
      "Epoch 18/100, Train Loss: 0.0244, Validation Loss: 0.0283\n",
      "Epoch 19/100, Train Loss: 0.0244, Validation Loss: 0.0284\n",
      "Epoch 20/100, Train Loss: 0.0244, Validation Loss: 0.0283\n",
      "Epoch 21/100, Train Loss: 0.0243, Validation Loss: 0.0286\n",
      "Epoch 22/100, Train Loss: 0.0243, Validation Loss: 0.0285\n",
      "Epoch 23/100, Train Loss: 0.0242, Validation Loss: 0.0285\n",
      "Epoch 00023: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 24/100, Train Loss: 0.0240, Validation Loss: 0.0277\n",
      "Epoch 25/100, Train Loss: 0.0239, Validation Loss: 0.0277\n",
      "Epoch 26/100, Train Loss: 0.0238, Validation Loss: 0.0277\n",
      "Epoch 27/100, Train Loss: 0.0239, Validation Loss: 0.0276\n",
      "Epoch 28/100, Train Loss: 0.0238, Validation Loss: 0.0278\n",
      "Epoch 29/100, Train Loss: 0.0238, Validation Loss: 0.0278\n",
      "Epoch 30/100, Train Loss: 0.0237, Validation Loss: 0.0279\n",
      "Epoch 31/100, Train Loss: 0.0237, Validation Loss: 0.0278\n",
      "Epoch 32/100, Train Loss: 0.0237, Validation Loss: 0.0279\n",
      "Epoch 33/100, Train Loss: 0.0237, Validation Loss: 0.0281\n",
      "Epoch 34/100, Train Loss: 0.0236, Validation Loss: 0.0281\n",
      "Epoch 00034: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 35/100, Train Loss: 0.0234, Validation Loss: 0.0273\n",
      "Epoch 36/100, Train Loss: 0.0233, Validation Loss: 0.0272\n",
      "Epoch 37/100, Train Loss: 0.0233, Validation Loss: 0.0273\n",
      "Epoch 38/100, Train Loss: 0.0233, Validation Loss: 0.0273\n",
      "Epoch 39/100, Train Loss: 0.0232, Validation Loss: 0.0274\n",
      "Epoch 40/100, Train Loss: 0.0232, Validation Loss: 0.0273\n",
      "Epoch 41/100, Train Loss: 0.0232, Validation Loss: 0.0274\n",
      "Epoch 42/100, Train Loss: 0.0232, Validation Loss: 0.0275\n",
      "Epoch 43/100, Train Loss: 0.0231, Validation Loss: 0.0275\n",
      "Epoch 44/100, Train Loss: 0.0231, Validation Loss: 0.0275\n",
      "Epoch 45/100, Train Loss: 0.0231, Validation Loss: 0.0275\n",
      "Epoch 00045: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 46/100, Train Loss: 0.0229, Validation Loss: 0.0269\n",
      "Epoch 47/100, Train Loss: 0.0228, Validation Loss: 0.0270\n",
      "Epoch 48/100, Train Loss: 0.0228, Validation Loss: 0.0270\n",
      "Epoch 49/100, Train Loss: 0.0228, Validation Loss: 0.0270\n",
      "Epoch 50/100, Train Loss: 0.0227, Validation Loss: 0.0271\n",
      "Epoch 51/100, Train Loss: 0.0228, Validation Loss: 0.0270\n",
      "Epoch 52/100, Train Loss: 0.0227, Validation Loss: 0.0272\n",
      "Epoch 53/100, Train Loss: 0.0227, Validation Loss: 0.0270\n",
      "Epoch 54/100, Train Loss: 0.0227, Validation Loss: 0.0272\n",
      "Epoch 55/100, Train Loss: 0.0227, Validation Loss: 0.0272\n",
      "Epoch 56/100, Train Loss: 0.0226, Validation Loss: 0.0273\n",
      "Epoch 00056: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 57/100, Train Loss: 0.0225, Validation Loss: 0.0267\n",
      "Epoch 58/100, Train Loss: 0.0224, Validation Loss: 0.0268\n",
      "Epoch 59/100, Train Loss: 0.0224, Validation Loss: 0.0267\n",
      "Epoch 60/100, Train Loss: 0.0223, Validation Loss: 0.0269\n",
      "Epoch 61/100, Train Loss: 0.0223, Validation Loss: 0.0269\n",
      "Epoch 62/100, Train Loss: 0.0223, Validation Loss: 0.0269\n",
      "Epoch 63/100, Train Loss: 0.0223, Validation Loss: 0.0268\n",
      "Epoch 64/100, Train Loss: 0.0223, Validation Loss: 0.0270\n",
      "Epoch 65/100, Train Loss: 0.0223, Validation Loss: 0.0270\n",
      "Epoch 66/100, Train Loss: 0.0222, Validation Loss: 0.0270\n",
      "Epoch 67/100, Train Loss: 0.0222, Validation Loss: 0.0270\n",
      "Epoch 00067: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 68/100, Train Loss: 0.0221, Validation Loss: 0.0265\n",
      "Epoch 69/100, Train Loss: 0.0220, Validation Loss: 0.0266\n",
      "Epoch 70/100, Train Loss: 0.0220, Validation Loss: 0.0267\n",
      "Epoch 71/100, Train Loss: 0.0220, Validation Loss: 0.0268\n",
      "Epoch 72/100, Train Loss: 0.0219, Validation Loss: 0.0268\n",
      "Epoch 73/100, Train Loss: 0.0220, Validation Loss: 0.0267\n",
      "Epoch 74/100, Train Loss: 0.0219, Validation Loss: 0.0268\n",
      "Epoch 75/100, Train Loss: 0.0219, Validation Loss: 0.0268\n",
      "Epoch 76/100, Train Loss: 0.0219, Validation Loss: 0.0268\n",
      "Epoch 77/100, Train Loss: 0.0219, Validation Loss: 0.0268\n",
      "Epoch 78/100, Train Loss: 0.0219, Validation Loss: 0.0268\n",
      "Epoch 00078: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 79/100, Train Loss: 0.0217, Validation Loss: 0.0265\n",
      "Epoch 80/100, Train Loss: 0.0217, Validation Loss: 0.0265\n",
      "Epoch 81/100, Train Loss: 0.0217, Validation Loss: 0.0265\n",
      "Epoch 82/100, Train Loss: 0.0217, Validation Loss: 0.0265\n",
      "Epoch 83/100, Train Loss: 0.0216, Validation Loss: 0.0266\n",
      "Epoch 84/100, Train Loss: 0.0216, Validation Loss: 0.0266\n",
      "Epoch 85/100, Train Loss: 0.0216, Validation Loss: 0.0266\n",
      "Epoch 86/100, Train Loss: 0.0216, Validation Loss: 0.0266\n",
      "Epoch 87/100, Train Loss: 0.0216, Validation Loss: 0.0266\n",
      "Epoch 88/100, Train Loss: 0.0215, Validation Loss: 0.0267\n",
      "Epoch 89/100, Train Loss: 0.0215, Validation Loss: 0.0267\n",
      "Epoch 00089: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 90/100, Train Loss: 0.0214, Validation Loss: 0.0265\n",
      "Epoch 91/100, Train Loss: 0.0214, Validation Loss: 0.0264\n",
      "Epoch 92/100, Train Loss: 0.0214, Validation Loss: 0.0264\n",
      "Epoch 93/100, Train Loss: 0.0213, Validation Loss: 0.0266\n",
      "Epoch 94/100, Train Loss: 0.0213, Validation Loss: 0.0265\n",
      "Epoch 95/100, Train Loss: 0.0213, Validation Loss: 0.0265\n",
      "Epoch 96/100, Train Loss: 0.0213, Validation Loss: 0.0266\n",
      "Epoch 97/100, Train Loss: 0.0212, Validation Loss: 0.0266\n",
      "Epoch 98/100, Train Loss: 0.0212, Validation Loss: 0.0266\n",
      "Epoch 99/100, Train Loss: 0.0212, Validation Loss: 0.0265\n",
      "Epoch 100/100, Train Loss: 0.0212, Validation Loss: 0.0266\n",
      "Epoch 00100: reducing learning rate of group 0 to 3.8742e-04.\n",
      "Fold 7 -> RMSE: 0.1558, MAE: 0.1142, R²: 0.3200\n",
      "\n",
      "Training Fold 8/10...\n",
      "Epoch 1/100, Train Loss: 0.0341, Validation Loss: 0.0254\n",
      "loss: 2.0604092333451263 2.0604092333451263\n",
      "Epoch 2/100, Train Loss: 0.0272, Validation Loss: 0.0245\n",
      "loss: 1.9865814724480515 1.9865814724480515\n",
      "Epoch 3/100, Train Loss: 0.0263, Validation Loss: 0.0247\n",
      "Epoch 4/100, Train Loss: 0.0260, Validation Loss: 0.0249\n",
      "Epoch 5/100, Train Loss: 0.0258, Validation Loss: 0.0252\n",
      "Epoch 6/100, Train Loss: 0.0257, Validation Loss: 0.0252\n",
      "Epoch 7/100, Train Loss: 0.0256, Validation Loss: 0.0253\n",
      "Epoch 8/100, Train Loss: 0.0256, Validation Loss: 0.0254\n",
      "Epoch 9/100, Train Loss: 0.0255, Validation Loss: 0.0255\n",
      "Epoch 10/100, Train Loss: 0.0255, Validation Loss: 0.0254\n",
      "Epoch 11/100, Train Loss: 0.0254, Validation Loss: 0.0254\n",
      "Epoch 12/100, Train Loss: 0.0254, Validation Loss: 0.0255\n",
      "Epoch 13/100, Train Loss: 0.0253, Validation Loss: 0.0256\n",
      "Epoch 00013: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 14/100, Train Loss: 0.0251, Validation Loss: 0.0247\n",
      "Epoch 15/100, Train Loss: 0.0250, Validation Loss: 0.0248\n",
      "Epoch 16/100, Train Loss: 0.0250, Validation Loss: 0.0247\n",
      "Epoch 17/100, Train Loss: 0.0249, Validation Loss: 0.0247\n",
      "Epoch 18/100, Train Loss: 0.0249, Validation Loss: 0.0248\n",
      "Epoch 19/100, Train Loss: 0.0248, Validation Loss: 0.0248\n",
      "Epoch 20/100, Train Loss: 0.0248, Validation Loss: 0.0248\n",
      "Epoch 21/100, Train Loss: 0.0248, Validation Loss: 0.0248\n",
      "Epoch 22/100, Train Loss: 0.0248, Validation Loss: 0.0248\n",
      "Epoch 23/100, Train Loss: 0.0247, Validation Loss: 0.0248\n",
      "Epoch 24/100, Train Loss: 0.0247, Validation Loss: 0.0248\n",
      "Epoch 00024: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 25/100, Train Loss: 0.0245, Validation Loss: 0.0241\n",
      "loss: 1.9487037607582351 1.9487037607582351\n",
      "Epoch 26/100, Train Loss: 0.0245, Validation Loss: 0.0241\n",
      "Epoch 27/100, Train Loss: 0.0244, Validation Loss: 0.0241\n",
      "Epoch 28/100, Train Loss: 0.0244, Validation Loss: 0.0241\n",
      "Epoch 29/100, Train Loss: 0.0243, Validation Loss: 0.0241\n",
      "Epoch 30/100, Train Loss: 0.0243, Validation Loss: 0.0241\n",
      "Epoch 31/100, Train Loss: 0.0243, Validation Loss: 0.0240\n",
      "loss: 1.9456107318736713 1.9456107318736713\n",
      "Epoch 32/100, Train Loss: 0.0243, Validation Loss: 0.0242\n",
      "Epoch 33/100, Train Loss: 0.0242, Validation Loss: 0.0242\n",
      "Epoch 34/100, Train Loss: 0.0242, Validation Loss: 0.0243\n",
      "Epoch 35/100, Train Loss: 0.0242, Validation Loss: 0.0243\n",
      "Epoch 36/100, Train Loss: 0.0242, Validation Loss: 0.0243\n",
      "Epoch 37/100, Train Loss: 0.0241, Validation Loss: 0.0243\n",
      "Epoch 38/100, Train Loss: 0.0241, Validation Loss: 0.0243\n",
      "Epoch 39/100, Train Loss: 0.0241, Validation Loss: 0.0243\n",
      "Epoch 40/100, Train Loss: 0.0241, Validation Loss: 0.0243\n",
      "Epoch 41/100, Train Loss: 0.0241, Validation Loss: 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 0.0240, Validation Loss: 0.0242\n",
      "Epoch 00042: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 43/100, Train Loss: 0.0239, Validation Loss: 0.0237\n",
      "loss: 1.916831559451282 1.916831559451282\n",
      "Epoch 44/100, Train Loss: 0.0238, Validation Loss: 0.0237\n",
      "Epoch 45/100, Train Loss: 0.0238, Validation Loss: 0.0238\n",
      "Epoch 46/100, Train Loss: 0.0238, Validation Loss: 0.0237\n",
      "Epoch 47/100, Train Loss: 0.0237, Validation Loss: 0.0238\n",
      "Epoch 48/100, Train Loss: 0.0237, Validation Loss: 0.0238\n",
      "Epoch 49/100, Train Loss: 0.0237, Validation Loss: 0.0238\n",
      "Epoch 50/100, Train Loss: 0.0237, Validation Loss: 0.0236\n",
      "loss: 1.9126431749539279 1.9126431749539279\n",
      "Epoch 51/100, Train Loss: 0.0236, Validation Loss: 0.0238\n",
      "Epoch 52/100, Train Loss: 0.0236, Validation Loss: 0.0238\n",
      "Epoch 53/100, Train Loss: 0.0236, Validation Loss: 0.0236\n",
      "loss: 1.9116661944622138 1.9116661944622138\n",
      "Epoch 54/100, Train Loss: 0.0236, Validation Loss: 0.0238\n",
      "Epoch 55/100, Train Loss: 0.0236, Validation Loss: 0.0237\n",
      "Epoch 56/100, Train Loss: 0.0236, Validation Loss: 0.0238\n",
      "Epoch 57/100, Train Loss: 0.0235, Validation Loss: 0.0237\n",
      "Epoch 58/100, Train Loss: 0.0235, Validation Loss: 0.0238\n",
      "Epoch 59/100, Train Loss: 0.0235, Validation Loss: 0.0238\n",
      "Epoch 60/100, Train Loss: 0.0235, Validation Loss: 0.0238\n",
      "Epoch 61/100, Train Loss: 0.0235, Validation Loss: 0.0239\n",
      "Epoch 62/100, Train Loss: 0.0235, Validation Loss: 0.0238\n",
      "Epoch 63/100, Train Loss: 0.0235, Validation Loss: 0.0239\n",
      "Epoch 64/100, Train Loss: 0.0234, Validation Loss: 0.0238\n",
      "Epoch 00064: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 65/100, Train Loss: 0.0233, Validation Loss: 0.0234\n",
      "loss: 1.8931970603385793 1.8931970603385793\n",
      "Epoch 66/100, Train Loss: 0.0232, Validation Loss: 0.0233\n",
      "loss: 1.8856426317668138 1.8856426317668138\n",
      "Epoch 67/100, Train Loss: 0.0232, Validation Loss: 0.0234\n",
      "Epoch 68/100, Train Loss: 0.0232, Validation Loss: 0.0234\n",
      "Epoch 69/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 70/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 71/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 72/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 73/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 74/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 75/100, Train Loss: 0.0231, Validation Loss: 0.0234\n",
      "Epoch 76/100, Train Loss: 0.0231, Validation Loss: 0.0233\n",
      "Epoch 77/100, Train Loss: 0.0230, Validation Loss: 0.0233\n",
      "Epoch 00077: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 78/100, Train Loss: 0.0229, Validation Loss: 0.0229\n",
      "loss: 1.8548506389434216 1.8548506389434216\n",
      "Epoch 79/100, Train Loss: 0.0229, Validation Loss: 0.0229\n",
      "Epoch 80/100, Train Loss: 0.0228, Validation Loss: 0.0228\n",
      "loss: 1.8463913358853574 1.8463913358853574\n",
      "Epoch 81/100, Train Loss: 0.0228, Validation Loss: 0.0229\n",
      "Epoch 82/100, Train Loss: 0.0228, Validation Loss: 0.0229\n",
      "Epoch 83/100, Train Loss: 0.0228, Validation Loss: 0.0230\n",
      "Epoch 84/100, Train Loss: 0.0227, Validation Loss: 0.0229\n",
      "Epoch 85/100, Train Loss: 0.0227, Validation Loss: 0.0230\n",
      "Epoch 86/100, Train Loss: 0.0227, Validation Loss: 0.0230\n",
      "Epoch 87/100, Train Loss: 0.0227, Validation Loss: 0.0230\n",
      "Epoch 88/100, Train Loss: 0.0227, Validation Loss: 0.0231\n",
      "Epoch 89/100, Train Loss: 0.0226, Validation Loss: 0.0231\n",
      "Epoch 90/100, Train Loss: 0.0226, Validation Loss: 0.0230\n",
      "Epoch 91/100, Train Loss: 0.0226, Validation Loss: 0.0230\n",
      "Epoch 00091: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 92/100, Train Loss: 0.0225, Validation Loss: 0.0226\n",
      "loss: 1.8344841678235753 1.8344841678235753\n",
      "Epoch 93/100, Train Loss: 0.0224, Validation Loss: 0.0226\n",
      "loss: 1.8333807495528163 1.8333807495528163\n",
      "Epoch 94/100, Train Loss: 0.0224, Validation Loss: 0.0227\n",
      "Epoch 95/100, Train Loss: 0.0224, Validation Loss: 0.0227\n",
      "Epoch 96/100, Train Loss: 0.0224, Validation Loss: 0.0228\n",
      "Epoch 97/100, Train Loss: 0.0224, Validation Loss: 0.0227\n",
      "Epoch 98/100, Train Loss: 0.0223, Validation Loss: 0.0228\n",
      "Epoch 99/100, Train Loss: 0.0224, Validation Loss: 0.0227\n",
      "Epoch 100/100, Train Loss: 0.0223, Validation Loss: 0.0228\n",
      "Fold 8 -> RMSE: 0.1504, MAE: 0.1127, R²: 0.3217\n",
      "\n",
      "Training Fold 9/10...\n",
      "Epoch 1/100, Train Loss: 0.0314, Validation Loss: 0.0243\n",
      "loss: 1.968775694622991 1.968775694622991\n",
      "Epoch 2/100, Train Loss: 0.0244, Validation Loss: 0.0243\n",
      "Epoch 3/100, Train Loss: 0.0238, Validation Loss: 0.0245\n",
      "Epoch 4/100, Train Loss: 0.0236, Validation Loss: 0.0248\n",
      "Epoch 5/100, Train Loss: 0.0235, Validation Loss: 0.0251\n",
      "Epoch 6/100, Train Loss: 0.0233, Validation Loss: 0.0252\n",
      "Epoch 7/100, Train Loss: 0.0233, Validation Loss: 0.0255\n",
      "Epoch 8/100, Train Loss: 0.0232, Validation Loss: 0.0256\n",
      "Epoch 9/100, Train Loss: 0.0231, Validation Loss: 0.0257\n",
      "Epoch 10/100, Train Loss: 0.0231, Validation Loss: 0.0261\n",
      "Epoch 11/100, Train Loss: 0.0230, Validation Loss: 0.0260\n",
      "Epoch 12/100, Train Loss: 0.0230, Validation Loss: 0.0263\n",
      "Epoch 00012: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 13/100, Train Loss: 0.0228, Validation Loss: 0.0262\n",
      "Epoch 14/100, Train Loss: 0.0227, Validation Loss: 0.0262\n",
      "Epoch 15/100, Train Loss: 0.0227, Validation Loss: 0.0264\n",
      "Epoch 16/100, Train Loss: 0.0227, Validation Loss: 0.0263\n",
      "Epoch 17/100, Train Loss: 0.0226, Validation Loss: 0.0264\n",
      "Epoch 18/100, Train Loss: 0.0226, Validation Loss: 0.0265\n",
      "Epoch 19/100, Train Loss: 0.0226, Validation Loss: 0.0267\n",
      "Epoch 20/100, Train Loss: 0.0225, Validation Loss: 0.0267\n",
      "Epoch 21/100, Train Loss: 0.0225, Validation Loss: 0.0266\n",
      "Epoch 22/100, Train Loss: 0.0225, Validation Loss: 0.0268\n",
      "Epoch 23/100, Train Loss: 0.0224, Validation Loss: 0.0268\n",
      "Epoch 00023: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 24/100, Train Loss: 0.0223, Validation Loss: 0.0267\n",
      "Epoch 25/100, Train Loss: 0.0222, Validation Loss: 0.0268\n",
      "Epoch 26/100, Train Loss: 0.0222, Validation Loss: 0.0267\n",
      "Epoch 27/100, Train Loss: 0.0222, Validation Loss: 0.0269\n",
      "Epoch 28/100, Train Loss: 0.0222, Validation Loss: 0.0269\n",
      "Epoch 29/100, Train Loss: 0.0221, Validation Loss: 0.0269\n",
      "Epoch 30/100, Train Loss: 0.0221, Validation Loss: 0.0269\n",
      "Epoch 31/100, Train Loss: 0.0221, Validation Loss: 0.0271\n",
      "Epoch 32/100, Train Loss: 0.0221, Validation Loss: 0.0270\n",
      "Epoch 33/100, Train Loss: 0.0220, Validation Loss: 0.0271\n",
      "Epoch 34/100, Train Loss: 0.0220, Validation Loss: 0.0271\n",
      "Epoch 00034: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 35/100, Train Loss: 0.0218, Validation Loss: 0.0270\n",
      "Epoch 36/100, Train Loss: 0.0218, Validation Loss: 0.0271\n",
      "Epoch 37/100, Train Loss: 0.0218, Validation Loss: 0.0270\n",
      "Epoch 38/100, Train Loss: 0.0218, Validation Loss: 0.0272\n",
      "Epoch 39/100, Train Loss: 0.0218, Validation Loss: 0.0271\n",
      "Epoch 40/100, Train Loss: 0.0217, Validation Loss: 0.0271\n",
      "Epoch 41/100, Train Loss: 0.0217, Validation Loss: 0.0271\n",
      "Epoch 42/100, Train Loss: 0.0217, Validation Loss: 0.0271\n",
      "Epoch 43/100, Train Loss: 0.0217, Validation Loss: 0.0272\n",
      "Epoch 44/100, Train Loss: 0.0217, Validation Loss: 0.0273\n",
      "Epoch 45/100, Train Loss: 0.0217, Validation Loss: 0.0273\n",
      "Epoch 00045: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 46/100, Train Loss: 0.0215, Validation Loss: 0.0273\n",
      "Epoch 47/100, Train Loss: 0.0214, Validation Loss: 0.0273\n",
      "Epoch 48/100, Train Loss: 0.0214, Validation Loss: 0.0273\n",
      "Epoch 49/100, Train Loss: 0.0214, Validation Loss: 0.0275\n",
      "Epoch 50/100, Train Loss: 0.0214, Validation Loss: 0.0273\n",
      "Epoch 51/100, Train Loss: 0.0214, Validation Loss: 0.0274\n",
      "Epoch 52/100, Train Loss: 0.0213, Validation Loss: 0.0274\n",
      "Epoch 53/100, Train Loss: 0.0213, Validation Loss: 0.0274\n",
      "Epoch 54/100, Train Loss: 0.0213, Validation Loss: 0.0274\n",
      "Epoch 55/100, Train Loss: 0.0213, Validation Loss: 0.0275\n",
      "Epoch 56/100, Train Loss: 0.0213, Validation Loss: 0.0276\n",
      "Epoch 00056: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 57/100, Train Loss: 0.0212, Validation Loss: 0.0275\n",
      "Epoch 58/100, Train Loss: 0.0211, Validation Loss: 0.0275\n",
      "Epoch 59/100, Train Loss: 0.0211, Validation Loss: 0.0275\n",
      "Epoch 60/100, Train Loss: 0.0211, Validation Loss: 0.0275\n",
      "Epoch 61/100, Train Loss: 0.0210, Validation Loss: 0.0275\n",
      "Epoch 62/100, Train Loss: 0.0211, Validation Loss: 0.0276\n",
      "Epoch 63/100, Train Loss: 0.0210, Validation Loss: 0.0275\n",
      "Epoch 64/100, Train Loss: 0.0210, Validation Loss: 0.0275\n",
      "Epoch 65/100, Train Loss: 0.0210, Validation Loss: 0.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 0.0210, Validation Loss: 0.0276\n",
      "Epoch 67/100, Train Loss: 0.0209, Validation Loss: 0.0276\n",
      "Epoch 00067: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 68/100, Train Loss: 0.0208, Validation Loss: 0.0277\n",
      "Epoch 69/100, Train Loss: 0.0208, Validation Loss: 0.0278\n",
      "Epoch 70/100, Train Loss: 0.0208, Validation Loss: 0.0277\n",
      "Epoch 71/100, Train Loss: 0.0208, Validation Loss: 0.0276\n",
      "Epoch 72/100, Train Loss: 0.0208, Validation Loss: 0.0277\n",
      "Epoch 73/100, Train Loss: 0.0207, Validation Loss: 0.0277\n",
      "Epoch 74/100, Train Loss: 0.0207, Validation Loss: 0.0278\n",
      "Epoch 75/100, Train Loss: 0.0207, Validation Loss: 0.0278\n",
      "Epoch 76/100, Train Loss: 0.0207, Validation Loss: 0.0278\n",
      "Epoch 77/100, Train Loss: 0.0207, Validation Loss: 0.0277\n",
      "Epoch 78/100, Train Loss: 0.0207, Validation Loss: 0.0278\n",
      "Epoch 00078: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 79/100, Train Loss: 0.0206, Validation Loss: 0.0279\n",
      "Epoch 80/100, Train Loss: 0.0206, Validation Loss: 0.0280\n",
      "Epoch 81/100, Train Loss: 0.0205, Validation Loss: 0.0280\n",
      "Epoch 82/100, Train Loss: 0.0205, Validation Loss: 0.0279\n",
      "Epoch 83/100, Train Loss: 0.0205, Validation Loss: 0.0279\n",
      "Epoch 84/100, Train Loss: 0.0205, Validation Loss: 0.0279\n",
      "Epoch 85/100, Train Loss: 0.0205, Validation Loss: 0.0279\n",
      "Epoch 86/100, Train Loss: 0.0204, Validation Loss: 0.0279\n",
      "Epoch 87/100, Train Loss: 0.0204, Validation Loss: 0.0280\n",
      "Epoch 88/100, Train Loss: 0.0204, Validation Loss: 0.0279\n",
      "Epoch 89/100, Train Loss: 0.0204, Validation Loss: 0.0280\n",
      "Epoch 00089: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 90/100, Train Loss: 0.0203, Validation Loss: 0.0282\n",
      "Epoch 91/100, Train Loss: 0.0203, Validation Loss: 0.0281\n",
      "Epoch 92/100, Train Loss: 0.0203, Validation Loss: 0.0281\n",
      "Epoch 93/100, Train Loss: 0.0202, Validation Loss: 0.0282\n",
      "Epoch 94/100, Train Loss: 0.0202, Validation Loss: 0.0281\n",
      "Epoch 95/100, Train Loss: 0.0202, Validation Loss: 0.0282\n",
      "Epoch 96/100, Train Loss: 0.0202, Validation Loss: 0.0281\n",
      "Epoch 97/100, Train Loss: 0.0202, Validation Loss: 0.0282\n",
      "Epoch 98/100, Train Loss: 0.0202, Validation Loss: 0.0282\n",
      "Epoch 99/100, Train Loss: 0.0202, Validation Loss: 0.0281\n",
      "Epoch 100/100, Train Loss: 0.0202, Validation Loss: 0.0282\n",
      "Epoch 00100: reducing learning rate of group 0 to 3.8742e-04.\n",
      "Fold 9 -> RMSE: 0.1559, MAE: 0.1162, R²: 0.5308\n",
      "\n",
      "Training Fold 10/10...\n",
      "Epoch 1/100, Train Loss: 0.0301, Validation Loss: 0.0374\n",
      "loss: 3.029136810208229 3.029136810208229\n",
      "Epoch 2/100, Train Loss: 0.0240, Validation Loss: 0.0359\n",
      "loss: 2.905054926894991 2.905054926894991\n",
      "Epoch 3/100, Train Loss: 0.0233, Validation Loss: 0.0360\n",
      "Epoch 4/100, Train Loss: 0.0230, Validation Loss: 0.0362\n",
      "Epoch 5/100, Train Loss: 0.0229, Validation Loss: 0.0362\n",
      "Epoch 6/100, Train Loss: 0.0228, Validation Loss: 0.0366\n",
      "Epoch 7/100, Train Loss: 0.0227, Validation Loss: 0.0369\n",
      "Epoch 8/100, Train Loss: 0.0226, Validation Loss: 0.0371\n",
      "Epoch 9/100, Train Loss: 0.0225, Validation Loss: 0.0370\n",
      "Epoch 10/100, Train Loss: 0.0225, Validation Loss: 0.0375\n",
      "Epoch 11/100, Train Loss: 0.0224, Validation Loss: 0.0378\n",
      "Epoch 12/100, Train Loss: 0.0224, Validation Loss: 0.0378\n",
      "Epoch 13/100, Train Loss: 0.0224, Validation Loss: 0.0379\n",
      "Epoch 00013: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 14/100, Train Loss: 0.0221, Validation Loss: 0.0372\n",
      "Epoch 15/100, Train Loss: 0.0220, Validation Loss: 0.0373\n",
      "Epoch 16/100, Train Loss: 0.0220, Validation Loss: 0.0374\n",
      "Epoch 17/100, Train Loss: 0.0220, Validation Loss: 0.0376\n",
      "Epoch 18/100, Train Loss: 0.0220, Validation Loss: 0.0375\n",
      "Epoch 19/100, Train Loss: 0.0219, Validation Loss: 0.0377\n",
      "Epoch 20/100, Train Loss: 0.0219, Validation Loss: 0.0379\n",
      "Epoch 21/100, Train Loss: 0.0219, Validation Loss: 0.0378\n",
      "Epoch 22/100, Train Loss: 0.0218, Validation Loss: 0.0379\n",
      "Epoch 23/100, Train Loss: 0.0218, Validation Loss: 0.0379\n",
      "Epoch 24/100, Train Loss: 0.0219, Validation Loss: 0.0381\n",
      "Epoch 00024: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 25/100, Train Loss: 0.0216, Validation Loss: 0.0372\n",
      "Epoch 26/100, Train Loss: 0.0216, Validation Loss: 0.0373\n",
      "Epoch 27/100, Train Loss: 0.0216, Validation Loss: 0.0374\n",
      "Epoch 28/100, Train Loss: 0.0215, Validation Loss: 0.0374\n",
      "Epoch 29/100, Train Loss: 0.0215, Validation Loss: 0.0373\n",
      "Epoch 30/100, Train Loss: 0.0215, Validation Loss: 0.0374\n",
      "Epoch 31/100, Train Loss: 0.0215, Validation Loss: 0.0375\n",
      "Epoch 32/100, Train Loss: 0.0215, Validation Loss: 0.0376\n",
      "Epoch 33/100, Train Loss: 0.0214, Validation Loss: 0.0373\n",
      "Epoch 34/100, Train Loss: 0.0214, Validation Loss: 0.0377\n",
      "Epoch 35/100, Train Loss: 0.0214, Validation Loss: 0.0377\n",
      "Epoch 00035: reducing learning rate of group 0 to 7.2900e-04.\n",
      "Epoch 36/100, Train Loss: 0.0212, Validation Loss: 0.0371\n",
      "Epoch 37/100, Train Loss: 0.0212, Validation Loss: 0.0370\n",
      "Epoch 38/100, Train Loss: 0.0212, Validation Loss: 0.0370\n",
      "Epoch 39/100, Train Loss: 0.0211, Validation Loss: 0.0370\n",
      "Epoch 40/100, Train Loss: 0.0211, Validation Loss: 0.0371\n",
      "Epoch 41/100, Train Loss: 0.0211, Validation Loss: 0.0372\n",
      "Epoch 42/100, Train Loss: 0.0211, Validation Loss: 0.0371\n",
      "Epoch 43/100, Train Loss: 0.0211, Validation Loss: 0.0372\n",
      "Epoch 44/100, Train Loss: 0.0210, Validation Loss: 0.0372\n",
      "Epoch 45/100, Train Loss: 0.0211, Validation Loss: 0.0373\n",
      "Epoch 46/100, Train Loss: 0.0210, Validation Loss: 0.0372\n",
      "Epoch 00046: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 47/100, Train Loss: 0.0208, Validation Loss: 0.0366\n",
      "Epoch 48/100, Train Loss: 0.0208, Validation Loss: 0.0366\n",
      "Epoch 49/100, Train Loss: 0.0208, Validation Loss: 0.0367\n",
      "Epoch 50/100, Train Loss: 0.0208, Validation Loss: 0.0366\n",
      "Epoch 51/100, Train Loss: 0.0208, Validation Loss: 0.0366\n",
      "Epoch 52/100, Train Loss: 0.0208, Validation Loss: 0.0367\n",
      "Epoch 53/100, Train Loss: 0.0207, Validation Loss: 0.0367\n",
      "Epoch 54/100, Train Loss: 0.0207, Validation Loss: 0.0366\n",
      "Epoch 55/100, Train Loss: 0.0207, Validation Loss: 0.0367\n",
      "Epoch 56/100, Train Loss: 0.0207, Validation Loss: 0.0367\n",
      "Epoch 57/100, Train Loss: 0.0207, Validation Loss: 0.0367\n",
      "Epoch 00057: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 58/100, Train Loss: 0.0206, Validation Loss: 0.0362\n",
      "Epoch 59/100, Train Loss: 0.0206, Validation Loss: 0.0361\n",
      "Epoch 60/100, Train Loss: 0.0205, Validation Loss: 0.0360\n",
      "Epoch 61/100, Train Loss: 0.0205, Validation Loss: 0.0361\n",
      "Epoch 62/100, Train Loss: 0.0205, Validation Loss: 0.0362\n",
      "Epoch 63/100, Train Loss: 0.0205, Validation Loss: 0.0361\n",
      "Epoch 64/100, Train Loss: 0.0205, Validation Loss: 0.0362\n",
      "Epoch 65/100, Train Loss: 0.0205, Validation Loss: 0.0362\n",
      "Epoch 66/100, Train Loss: 0.0204, Validation Loss: 0.0362\n",
      "Epoch 67/100, Train Loss: 0.0204, Validation Loss: 0.0363\n",
      "Epoch 68/100, Train Loss: 0.0204, Validation Loss: 0.0362\n",
      "Epoch 00068: reducing learning rate of group 0 to 5.3144e-04.\n",
      "Epoch 69/100, Train Loss: 0.0203, Validation Loss: 0.0354\n",
      "loss: 2.868935547452338 2.868935547452338\n",
      "Epoch 70/100, Train Loss: 0.0203, Validation Loss: 0.0355\n",
      "Epoch 71/100, Train Loss: 0.0203, Validation Loss: 0.0355\n",
      "Epoch 72/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 73/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 74/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 75/100, Train Loss: 0.0202, Validation Loss: 0.0354\n",
      "Epoch 76/100, Train Loss: 0.0202, Validation Loss: 0.0355\n",
      "Epoch 77/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 78/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 79/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 80/100, Train Loss: 0.0202, Validation Loss: 0.0356\n",
      "Epoch 00080: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 81/100, Train Loss: 0.0201, Validation Loss: 0.0350\n",
      "loss: 2.8344845772963936 2.8344845772963936\n",
      "Epoch 82/100, Train Loss: 0.0200, Validation Loss: 0.0350\n",
      "Epoch 83/100, Train Loss: 0.0200, Validation Loss: 0.0351\n",
      "Epoch 84/100, Train Loss: 0.0200, Validation Loss: 0.0351\n",
      "Epoch 85/100, Train Loss: 0.0200, Validation Loss: 0.0352\n",
      "Epoch 86/100, Train Loss: 0.0200, Validation Loss: 0.0351\n",
      "Epoch 87/100, Train Loss: 0.0200, Validation Loss: 0.0350\n",
      "loss: 2.83379212405859 2.83379212405859\n",
      "Epoch 88/100, Train Loss: 0.0200, Validation Loss: 0.0350\n",
      "Epoch 89/100, Train Loss: 0.0200, Validation Loss: 0.0350\n",
      "loss: 2.8335914424273483 2.8335914424273483\n",
      "Epoch 90/100, Train Loss: 0.0200, Validation Loss: 0.0350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 0.0199, Validation Loss: 0.0352\n",
      "Epoch 92/100, Train Loss: 0.0199, Validation Loss: 0.0351\n",
      "Epoch 93/100, Train Loss: 0.0199, Validation Loss: 0.0351\n",
      "Epoch 94/100, Train Loss: 0.0199, Validation Loss: 0.0351\n",
      "Epoch 95/100, Train Loss: 0.0199, Validation Loss: 0.0351\n",
      "Epoch 96/100, Train Loss: 0.0199, Validation Loss: 0.0352\n",
      "Epoch 97/100, Train Loss: 0.0199, Validation Loss: 0.0352\n",
      "Epoch 98/100, Train Loss: 0.0199, Validation Loss: 0.0352\n",
      "Epoch 00098: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 99/100, Train Loss: 0.0198, Validation Loss: 0.0347\n",
      "loss: 2.810788435347746 2.810788435347746\n",
      "Epoch 100/100, Train Loss: 0.0198, Validation Loss: 0.0347\n",
      "Fold 10 -> RMSE: 0.1863, MAE: 0.1244, R²: 0.3796\n",
      "\n",
      "Cross-validation Results:\n",
      "RMSE Mean: 0.1653, Std: 0.0218\n",
      "MAE Mean: 0.1221, Std: 0.0144\n",
      "R² Mean: 0.3417, Std: 0.1530\n"
     ]
    }
   ],
   "source": [
    "# 进行5折交叉验证\n",
    "epoch = 100 #设置训练轮数\n",
    "mean_rmse, mean_mae, mean_r2, rmse_std, mae_std, r2_std = train_kfold(model, data_list, mol_features, train_targets, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12b085",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# 以下为测试部分\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "385c5ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型测试函数\n",
    "def test_model(model, data_list, mol_features, targets):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    loss_fn = nn.MSELoss()\n",
    "    pred_list = []\n",
    "    targ_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data_list)):\n",
    "            data_ = data_list[i].to(device)\n",
    "#             mol_feature = torch.tensor(mol_features[i], dtype=torch.float32).to(device)\n",
    "#             target = torch.tensor(targets[i], dtype=torch.float32).to(device)\n",
    "            mol_feature = mol_features[i].clone().detach().to(device)\n",
    "            target = targets[i].clone().detach().to(device)\n",
    "            output = model(data_,mol_feature)\n",
    "            # print(output, target)\n",
    "            loss = loss_fn(output, target)\n",
    "            val_loss += loss.item()\n",
    "            pred_list.append(output.item())\n",
    "            targ_list.append(target.item())\n",
    "    rmse = np.sqrt(mean_squared_error(targ_list, pred_list))\n",
    "    mae = mean_absolute_error(targ_list, pred_list)\n",
    "    r2 = r2_score(targ_list, pred_list)\n",
    "    return val_loss / len(data_list), rmse, mae, r2, targ_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4f3365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集数据处理\n",
    "smiles_list_test = test_data['SMILES'].tolist()\n",
    "test_targets = test_data['IE'].values\n",
    "mol_features_test = test_data.drop(columns=['SMILES', 'IE']).values\n",
    "\n",
    "mol_features_test = torch.tensor(mol_features_test, dtype=torch.float32).to(device)\n",
    "test_targets = torch.tensor(test_targets, dtype=torch.float32).to(device)\n",
    "\n",
    "# 分子图特征提取\n",
    "featurization_params = FeaturizationParameters()\n",
    "data_list_test = []\n",
    "for smiles in smiles_list_test:\n",
    "    data, mol = smiles_to_graph(smiles, featurization_params)  # 传递 featurization_params\n",
    "    #print(data)\n",
    "    data_list_test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "332775c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集MSE误差 0.02118290853059188 \n",
      "训练集MAE误差 0.10177034137336452 \n",
      "训练集RMSE误差 0.14554349360446134 \n",
      "训练集R平方 0.505743211438527 \n",
      "训练集平均损失 0.021182908564468507 \n",
      "测试集MSE误差 0.03598839291627078 \n",
      "测试集MAE误差 0.13391769570963724 \n",
      "测试集RMSE误差 0.18970606979290563 \n",
      "测试集R平方 0.007345396739652288 \n",
      "测试集平均损失 0.03598839302318895\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "1.# 训练集\n",
    "train_val_loss, train_rmse, train_mae, train_r_square, train_target, train_pred = test_model(model, data_list, mol_features, train_targets)\n",
    "2.# 测试集\n",
    "test_val_loss, test_rmse, test_mae, test_r_square, test_target, test_pred = test_model(model, data_list_test, mol_features_test, test_targets)\n",
    "\n",
    "train_mse = train_rmse * train_rmse\n",
    "test_mse = test_rmse * test_rmse\n",
    "\n",
    "# 输出\n",
    "print('训练集MSE误差', train_mse, '\\n训练集MAE误差', train_mae,'\\n训练集RMSE误差', train_rmse, '\\n训练集R平方', train_r_square,\n",
    "      '\\n训练集平均损失', train_val_loss, '\\n测试集MSE误差', test_mse, '\\n测试集MAE误差', test_mae,'\\n测试集RMSE误差', test_rmse,\n",
    "      '\\n测试集R平方', test_r_square, '\\n测试集平均损失', test_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28a22b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.plot(train_target, train_target, color='yellow', linewidth=2)\n",
    "plt.scatter(train_target, train_pred,5,  color='red')\n",
    "#plt.scatter(train_target, y_pred_svm,5,  color='cyan')\n",
    "#plt.scatter(train_target, y_train_pred,10,  color='black')\n",
    "plt.title('缓蚀剂性能训练集')\n",
    "plt.xlabel('真实值')\n",
    "plt.ylabel('预测值')\n",
    "#plt.legend(('','rf','svm','gnn'))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b087ed0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.plot(test_target, test_target, color='yellow', linewidth=2)\n",
    "plt.scatter(test_target, y_pred_rf,5,  color='red')\n",
    "plt.scatter(test_target, y_pred_svm,5,  color='cyan')\n",
    "plt.scatter(test_target, test_pred,10,  color='black')\n",
    "plt.title('缓蚀剂性能测试集')\n",
    "plt.xlabel('真实值')\n",
    "plt.ylabel('预测值')\n",
    "plt.legend(('','rf','svm','gnn'))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d548e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecfp(mol, rad=2, bits=1024):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    morgan_gen = Chem.rdFingerprintGenerator.GetMorganGenerator(radius=rad, fpSize=bits)\n",
    "    fingerprint = morgan_gen.GetFingerprint(mol)\n",
    "    array = np.zeros(len(fingerprint))\n",
    "    DataStructs.ConvertToNumpyArray(fingerprint, array)\n",
    "    # array = Chem.rdFingerprintDescriptors.GetMorganFingerprint(mol, rad)\n",
    "    return array\n",
    "\n",
    "def readMol(df):\n",
    "    df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "    df['ecfp'] = df['mol'].apply(generate_ecfp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc2776f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = readMol(train_data)\n",
    "df_test = readMol(test_data)\n",
    "X_train = df_train['ecfp'].tolist()\n",
    "X_test = df_test['ecfp'].tolist()\n",
    "y_train = df_train['IE']\n",
    "y_test = df_test['IE']\n",
    "train_data = train_data.drop('ecfp', axis=1).drop('mol', axis=1)\n",
    "test_data = test_data.drop('ecfp', axis=1).drop('mol', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d121d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MSE: 0.0274\n",
      "SVM R2: 0.2443\n",
      "SVM RMSE: 0.1655\n",
      "SVM MAE: 0.1310\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svm = SVR()\n",
    "# 使用 GridSearchCV 进行超参数调优\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# 预测\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
    "rmse_svm  = np.sqrt(mse_svm)\n",
    "mae_svm = mean_absolute_error(y_test, y_pred_svm)\n",
    "r_square_svm = r2_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f'SVM MSE: {mse_svm:.4f}')\n",
    "print(f'SVM R2: {r_square_svm:.4f}')\n",
    "print(f'SVM RMSE: {rmse_svm:.4f}')\n",
    "print(f'SVM MAE: {mae_svm:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c197d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF MSE: 0.0307\n",
      "RF R2: 0.1521\n",
      "RF RMSE: 0.1753\n",
      "RF MAE: 0.1339\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf  = np.sqrt(mse_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r_square_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'RF MSE: {mse_rf:.4f}')\n",
    "print(f'RF R2: {r_square_rf:.4f}')\n",
    "print(f'RF RMSE: {rmse_rf:.4f}')\n",
    "print(f'RF MAE: {mae_rf:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
